\begin{document}

%************************************************
\chapter{General Introduction} \label{chp:general_intro}

%-------------------------------------------------------------------

\section{M dwarfs and the substellar realm} \label{chp:mdwarfs_intro}

\subsection{M dwarfs$\dots$}


For centuries, humans have gazed at the night sky, wondering what the bright objects up there might look like. Thanks to the technological advances in the last decades, which allow an ever more detailed exploration of our universe, we now know that most of our nearest neighbours were so faint that we could not see them with our naked eyes. Faint, cool, low-mass stars known as M dwarfs are by far the most common type of star in the Solar Neighbourhood \citep{henry1994,reid2004,bochanski2010,reyle2021,kirkpatrick2024}. As presented by \citet{reyle2021}, the ubiquity of M dwarfs is overwhelming in our vicinity (see Figure \ref{fig:4pc}), with three out of every four stars within 10\,pc being spectroscopically classified as M dwarfs \citep[see Table 2 in][]{henry2024}, often with planets orbiting around them. This abundance, together with their remarkable lifespan of tens of billions of years \citep{adams1997,laughlin1997}, makes them a fundamental piece in the study of Galactic structure and kinematics \citep{chabrier2003,chabrier2005,bochanski2007,caballero2008,ferguson2017,cortes2024}. Thus, an accurate characterisation of the M dwarf population, with masses ranging from $\sim0.6$\,$M_{\odot}$ to $\sim0.1$\,$M_{\odot}$ \citep{cifuentes_ucm} and located at the lower tail of the main sequence (see Figure \ref{fig:hr_mdwarfs}), is key to the understanding of our Galaxy.


One of the most active lines of research in stellar astrophysics at international level is the detection and characterisation of extrasolar planets. Along with projects dedicated to the search of terrestrial exoplanets in orbits up to the habitable zone of Sun-like stars, such as PLATO \citep{plato}, several programs have been established with the goal of identifying potentially habitable planets orbiting M dwarfs. Notable examples include the Transiting Exoplanet Survey Satellite \citep[TESS,][]{tess}, the Echelle Spectrograph for Rocky Exoplanet and Stable Spectroscopic Observations \citep[ESPRESSO,][]{pepe21} and its predecessor, the High-Accuracy Radial velocity Planet Searcher \citep[HARPS,][]{mayor2003,bonfils13}, or the Calar Alto high-Resolution search for M dwarfs with Exoearths with Near-infrared and optical Echelle Spectrographs \citep[CARMENES,][]{Quirrenbach16,Quirrenbach20}. The small size and low luminosity of M dwarfs, compared to Sun-like stars, make it easier to detect close-in terrestrial planets in their habitable zones \citep{zechmeister2019,Kossakowski2023,suarez2023,dreizler2024}. Moreover, M dwarfs have established themselves in recent years as very suitable targets in the search for Earth-like planets \citep{dressing2015,kopparapu2017,gillon2017,reiners2018,sabotta2021,nagel2023}, with  several studies confirming an elevated occurrence rate of Earth-like planets around M dwarfs \citep{gaidos2016,mulders2021,sabotta2021}.

The precise determination of the physical parameters of planet-hosting stars is crucial to improve our understanding of planetary formation and evolution, which depends fundamentally on the thorough characterisation of their host stars \citep{souto2017,cifuentes2020}. However, well-established photometric and spectroscopic methods for determining the stellar atmospheric parameters of M dwarfs encounter several pitfalls, mainly due to the particular features of their cool atmospheres. The low temperatures, between $\sim2300$\,K and $\sim3900$\,K, of these atmospheres enable the formation of diatomic and triatomic molecules, with a spectral sequence characterised by the presence of strong molecular absorption bands, such as TiO and VO \citep{joy1947,keenan1952,boeshaar1976}, as shown in Figure \ref{fig:hr_mdwarfs}. Moreover, for late M-dwarfs (M5 or later), the outermost layers of the atmosphere are cool enough to form dust and clouds, which makes the modelling of these atmospheres and the consequent determination of their stellar parameters even more complex. This is further aggravated by the inherent faintness of M dwarfs, which makes it difficult to obtain high-S/N, high-resolution spectra, and their frequent manifestation of strong stellar activity. Despite these problems, numerous efforts have been devoted to estimating photospheric parameters in M dwarfs, including effective temperature, surface gravity, and metallicity. Several methods have proven successful in inferring these parameters, such as fitting synthetic spectra \citep{bayo2017,pass18,Rajpurohit2018,pass2019,schw19,Souto2020,mar21,Sarmento2021}, pseudo-equivalent widths \citep{Mann2013,Mann2014,Neves2014,Khata2020,almendros2022},
spectral indices \citep{RojasAyala2010,bayo2011,Rojas2012,Khata2020}, empirical calibrations \citep{casagrande08,Neves2012,rojasayala2014,Rodriguez2019}, interferometry \citep{Boyajian2012,Rabus2019}, and machine learning  \citep{Sarro2018,Antoniadis2020,pass20,Li2021,bello2023,masbuitrago2024,rains2024}.

The main difference between M dwarfs and other stellar objects is that their stellar properties change significantly from early to late types. Especially, for spectral types $\sim M3-4$ and later \citep[masses below $0.35$\,$M_{\odot}$; ][]{chabrier1997}, M dwarfs become fully convective and experience a critical transition in their structure and behaviour. In this boundary, the radiative cores typical of earlier M dwarfs disappear and their interiors become fully convective, with energy transport dominated by convection throughout the stellar envelope \citep{delfosse1998,reiners2009}. As a result, a large fraction of low-mass stars, especially young, fast-rotating M dwarfs, are magnetically active, with a chromospheric activity often diagnosed by H$\alpha$ or Ca~{\sc ii} H and K line emission \citep{cincunegui2007,ibanezbustos2023}. After reaching the main sequence, low-mass stars slowly spin-down due to the loss of angular momentum by stellar winds, thus undergoing a decrease in their magnetic activity over time \citep{yang2017,davenport2019,raetz2020} that may also be dependent on stellar metallicity \citep{see24}. This abundant activity, combined with the proximity of the habitable zone of M dwarfs, makes exoplanets more exposed to energetic events related to stellar activity \citep{tilley2019,gunther2020,chen2021}, such as flares or coronal mass ejections, which are frequent in M dwarfs.

The faintness and low temperature of M dwarfs provide them with characteristics that push astronomers to the limit when it comes to accurately characterising them. But they are not the faintest. What do we find when we venture towards even lower masses? What separates our planet, the Earth, from the coolest stars?


\subsection{$\dots$and beyond} \label{sec:ucds_intro}

``WHAT distinguishes a star from a planet? Could we call Jupiter a failed star?'' This is how Dr. Lorne Nelson began his article on page 102 of volume 377 of the journal Nature in September 1995. Twenty-seven pages below, \citet{rebolo1995} reported the discovery of an object, in the young Pleiades star cluster, located on the boundary between the stars and the giant planets. \citet{kumar1963b,kumar1963} and \citet{hayashi1963} had first postulated the existence of this substellar objects, termed as ``brown dwarfs'' in 1975 by Jill Tarter \citep{tarter2014}, unable to maintain stable hydrogen ($^1$H) fusion in their interior due to their low mass. This substellar boundary is established for $\sim0.072$\,$M_{\odot}$ ($\sim75$\,$M_{\mathrm{J}}$), depending on the models and the metallicity, beyond which the low mass makes objects unable to reach sufficient internal pressure and temperature to sustain thermonuclear processes of hydrogen-to-helium conversion. However, up to masses of $\sim13$\,$M_{\mathrm{J}}$ \citep{chabrier2000} these substellar objects are massive enough to sustain deuterium fusion in their interiors at some point in their evolution, and this limit is often used to define the boundary between brown dwarfs and giant exoplanets.

Decades after they were first proposed theoretically, 1995 marked a turning point in the exploration of the substellar realm, with the first solid discoveries of brown dwarfs and exoplanets. First, \citet{basri1995} presented evidence of lithium in PPl 15, identifying this object as a brown dwarf just below the substellar limit. This ``lithium test'', or detection of lithium in the atmosphere, was of paramount importance for the detection of the first brown dwarfs and was first proposed by \citet{Rebolo1992} to distinguish between very low-mass stars and brown dwarfs close to the substellar boundary. Unlike very low-mass stars, objects with masses below $\sim0.060$\,$M_{\odot}$ \citep[see Figure 2 in][]{chabrier2000} cannot reach the $^{7}Li$ burning temperature and preserve a significant amount of their original Li content, so the substellar nature of brown dwarfs can be confirmed by spectroscopic detection of the Li 670.8\,nm resonance line. This is the test that \citet{rebolo1996} used to finally confirm the brown dwarf nature of Teide\,1 and Calar\,3. In late 1995, at the same conference where the discovery of the first extrasolar planet was announced, the discovery of a cool brown dwarf \citep[GJ\,229B; ][]{nakajima1995,oppenheimer1995} was also reported.

The ultracool dwarf domain covers very low-mass stars and substellar objects with spectral types M7 or later \citep{kirkpatrick1997}, including the extended L, T, and Y spectral types \citep{martin1997,martin1999b,kirkpatrick1999,burgasser2006,geballe2002,burningham2008,cushing2011}. With effective temperatures of $T_{\mathrm{eff}}\lesssim2800$\,K, the spectra of ultracool dwarfs are dominated by strong molecular absorption bands. The transition from late-M to L dwarfs (at about $2200$\,K) is characterised by the gradual disappearance of the TiO and VO oxide bands, the strengthening of H$_2$O and metal hydride (CrH, FeH, CaH) absorption bands, and a increasing steepness around the $6000-10000$\,$\AA$ interval \citep{kirkpatrick2000,reid2000,geballe2002}. Also, the neutral alkali metal absorption lines, especially Na~{\textsc{i}} and K~{\textsc{i}}, grow considerably by mid-L dwarfs in the optical. The beginning of the T dwarfs sequence, around $1300$\,K, is marked by the appearance of methane (CH$_4$) absorption in the near-infrared \textit{H} and \textit{K} bands, which strengthens along with H$_2$O absorption as the sequence evolves towards late-T spectral types. Due to the increasing depth of the CH$_4$ absorption bands, the flux in the \textit{H} and \textit{K} bands is reduced with respect to the \textit{J} band (see Figure \ref{fig:comp_l6t6}), and the near-infrared colours of T dwarfs become increasingly blue as compared to L dwarfs \citep{burgasser2002,geballe2002}. Finally, the transition to Y dwarfs, at about $500$\,K, is characterised by the presence of H$_2$O and ammonia (NH$_3$) photospheric clouds \citep{delorme2008,cushing2011}, in contrast to the CH$_4$ clouds typical of T dwarfs, and recent studies with the James Webb Space Telescope \citep[JWST,][]{jwst} have also found the presence of phosphine (PH$_3$) \citep{burgasser2024}.


The left panel in Figure \ref{fig:ucds_diag} shows a near-infrared $M_{\mathrm{J}}$ vs. $\textit{J}-\textit{H}$ colour-magnitude diagram of a clean sample of ultracool dwarfs with spectroscopic spectral classification. To obtain our sample, we queried the UltracoolSheet catalogue \citep{ucs} and applied selection criteria to retain only resolved ultracool dwarfs with reliable photometry and parallax, discarding objects with a photometric spectral type. The final sample contains $\sim1500$ ultracool dwarfs with a reliable spectroscopic classification of L0 or later. The colour-magnitude diagram shows how ultracool dwarfs, as they become fainter, evolve into redder $\textit{J}-\textit{H}$ colours until they reach the L/T transition. By spectral type L5, the photosphere is cool enough to allow the hydrogenation of CO to CH$_4$ \citep{noll2000,canty2015}, and CH$_4$ gradually becomes dominant over carbon monoxide (CO), typical of the photospheres of early- to mid-L objects. Throughout this transition to mid-T dwarfs, the absolute magnitude remains nearly constant while the $\textit{J}-\textit{H}$ colour grows bluer due to increased CH$_4$ absorption. Likewise, the right panel in Figure \ref{fig:ucds_diag} shows how the relation between $M_{\mathrm{J}}$ (and also effective temperature)  and spectral type is non-linear and exhibits a plateau in the L/T transition \citep{golimovsky2004,saumon2008,kirkpatrick2021}.


Discoveries of ultracool dwarfs have primarily been driven by wide-field optical and infrared imaging surveys such as the Deep Near Infrared Survey of the Southern Sky \citep[DENIS;][]{denis}, the Sloan Digital Sky Survey \citep[SDSS;][]{sdss}, the Two-Micron All Sky Survey \citep[2MASS;][]{2mass}, the UKIRT Infrared Deep Sky Survey \citep[UKIDSS; ][]{ukidss}, the Wide-Field Infrared Sky Explorer \citep[WISE;][]{wise}, the Panoramic Survey Telescope and Rapid Response System \citep[Pan-STARRS;][]{panstarrs}, and the Javalambre Photometric Local Universe Survey \citep[J-PLUS;][]{Cenarro2019}. The \textit{Gaia} mission \citep{gaiadr3} has also contributed to the discovery of ultracool dwarfs in the whole sky. Despite all these efforts, the 20\,pc census of ultracool dwarfs is still incomplete \citep{kirkpatrick2024}, with a completeness volume of 15\,pc and 11\,pc for spectral types later than $\sim$T8.5 and $\sim$Y0, respectively. A consolidated approach for the identification of ultracool dwarfs in these surveys is the definition of a locus in colour-colour or colour-magnitude diagrams in the optical (see Figure \ref{fig:ucds_ccopt}) or the infrared (see Figure \ref{fig:ucds_ccnir}) using previously known objects \citep{skrzypek2016,smart2017,panstarrs1,Reyle2018,carnero2019,masbuitrago2022,sarro2023,euclid_ero}.


Spectral classification, and its calibration to temperature or luminosity classes, is of utmost importance for characterising the ultracool dwarf (and any) astronomical population. There are several ways of doing this, such as direct comparison of the observed spectra with anchored optical \citep{kirkpatrick1999} and infrared \citep{burgasser2006,kirkpatrick2010,cushing2011} spectral standards. Late-M and L dwarfs classification is tied to the red optical region of the spectrum, while the T dwarfs are often characterised from the near-infrared region due to the presence of strong H$_2$O and CH$_4$ bands. Another approach is the classification through the measurement of different spectroscopic indices, defined as flux ratios that measure the strength of specific absorption or pseudocontinuum features \citep{kirkpatrick1995,martin1997,Martin1999,burgasser2007}. Over the last decade, analysis toolkits such as \texttt{SPLAT} \citep{splat}\,\footnote{\url{https://github.com/aburgasser/splat}}  have incredibly facilitated this classification task for the astronomical community. Once the spectral classification is done, it can be converted to effective temperature or luminosity following predefined empirical relations \citep{pecaut2013,filippazzo2015,kirkpatrick2021}.

These methodologies have proven to be broadly consistent throughout the literature, but how do we mine the large astronomical archives that make them possible? Most of the workflows followed in astronomical research require the combination of multi-wavelength data from different surveys. And here the Virtual Observatory is king. Moreover, the advent of huge volumes of data that will be provided in the coming years by missions such as \textit{Euclid} \citep{euclid} demand the development of fully automated solutions for ultracool dwarf identification and characterisation. Will machines fill this gap? Will deep learning be a cornerstone in the future study of the stunning ultracool dwarfs domain?



%-------------------------------------------------------------------

\section{From stars to data: the Virtual Observatory} \label{chp:vo_intro}

Just as a song means nothing if no one listens to it, data gains purpose only through the lens of analysis. And in the late 1990s and early 2000s, astronomy faced a crucial challenge in this aspect. The rapid advancement of astronomical instrumentation in recent decades has led to an exponential increase in the volume of astronomical data and the complexity of their processing. Until 1990, astronomical data were collected mainly with ground-based telescopes, but the launch of the Hubble Space Telescope \citep{bahcall1986} would bring a revolution in digital astronomy, with an unprecedented volume of data. However, it would not be alone up there, as other space observatories, such as the Infrared Astronomical Satellite \citep{iras} and the International Ultraviolet Explorer \citep{boggess1978}, a pioneer in the development of astronomical archives, were already in operation. During the 1990s, the digitisation of photographic plates enabled the generation of catalogues such as the Guide Star Catalog \citep{lasker1990,lasker1996} and the USNO \citep{monet1998,monet2003}. Notable catalogues in the last years of the 1990s were the Tycho-2 \citep{tycho2} collected by the ESA Hipparcos satellite, with two-colour photometric data for 2.5 million stars, and other catalogues such as the ROSAT All-Sky Survey \citep{rosat} or the NRAO VLA Sky Survey \citep{nvss}. The first data releases from large astronomical surveys, such as 2MASS in 1999 and SDSS in 2003, further fuelled this data revolution, ultimately breaking the Big Data barrier in the 2010s with the launch of the \textit{Gaia} telescope \citep{gaiadr1}. \textit{Gaia} is the mission that pushed astronomy into the petabyte\,\footnote{$1$\,petabyte $ = 1\,048\,576$\,gigabytes} domain, and  has revolutionised observational astronomy by providing the largest, most precise map of the Milky Way. In short, all these efforts by the scientific community have meant that we are now living in the era of large astronomical catalogues such as Pan-STARRS1 \citep{panstarrs}, \textit{Gaia} DR3 \citep{gaiadr3}, SDSS DR12 \citep{sdssdr12} or UKIDSS DR9 \citep{ukidssdr9}, among many others\,\footnote{A comprehensive list of large catalogues can be found at: \url{https://vizier.cds.unistra.fr/vizier/welcome/vizierbrowse.gml?bigcat}}. But this is only the beginning, and this data tsunami will only get bigger and bigger with the next generation of observatories such as the Vera C. Rubin Observatory \citep{ivezic2019}, the Square Kilometre Array \citep{dewdney2009}, or the Nancy Grace Roman Space Telescope \citep{mosby2020}.

The ability to fully utilize these vast datasets poses a major challenge to the astronomical community, and the Virtual Observatory (VO) is the response to this revolution. Just as 1995 was the year of the ultracool dwarfs, 2000 marked a turning point for data mining in astronomy. Two conferences held during the summer of this year, ``Virtual Observatories of the Future'' in Pasadena and ``Mining the Sky'' in Garching, laid the foundations for what two years later would become the International VO Alliance, or IVOA\,\footnote{\url{https://ivoa.net/}}. At its core, the VO is an international initiative aimed at removing the barriers imposed by the geographical and structural fragmentation of astronomical archives, by developing data standards and protocols\,\footnote{\url{https://www.ivoa.net/documents/}} to enable this interoperability. The main goal of the VO is to create a unified and interoperable system that allows astronomers to efficiently discover, retrieve, and analyse astronomical observations, models, and simulations, from multiple archives around the world.


A key aspect of the VO is the development of data discovery and mining tools that benefit from this data standardisation and enable the access and analysis of multi-wavelength data. \texttt{TOPCAT} \citep{Taylor2005} is a tool that allows interactive manipulation and visualisation of tabular data, making it easier for the astronomer to access source catalogues, and to compare these catalogues with local data. Moreover, the \texttt{Aladin} interactive sky atlas \citep{aladin} is a service that provides simultaneous access to digitised sky images, astronomical catalogues and archives. Within IVOA, individual countries have developed national VO initiatives that further support and implement the VO framework. One particularly successful example is the Spanish VO (SVO)\,\footnote{\url{https://svo.cab.inta-csic.es/main/index.php}}, established in 2004 and coordinated by Dr. Enrique Solano Márquez at the Centro de Astrobiología. The SVO has played a pivotal role in developing and deploying VO services, such as the VO Sed Analyzer (VOSA)\,\footnote{\url{http://svo2.cab.inta-csic.es/theory/vosa/}} \citep{vosa}, a tool that fits observed photometry to different collections of theoretical models to estimate physical properties, such as the effective temperature or luminosity. In addition, VOSA offers a wide range of functionalities to the user, such as the possibility of querying several VO catalogues to enlarge the input data of the sources studied. Another of the flagship services of the SVO is the \textit{Carlos Rodrigo} Filter Profile Service (FPS)\,\footnote{\url{http://svo2.cab.inta-csic.es/theory/fps/}} \citep{fps}, which is widely used by the astronomical community. The FPS contains detailed information on more than ten thousand photometric filters, the largest public collection of its kind. In addition, the SVO is responsible for the management of important astronomical archives\,\footnote{\url{https://svo.cab.inta-csic.es/docs/index.php?pagename=Archives}}, notably the GTC and Calar Alto archives.

In modern astronomy, most of the research studies require the use of multi-wavelength data that is often stored in separate archives, and with different formats or query mechanisms. Without standardisation and interoperability between the archives, conducting multi-wavelength or multi-messenger \citep{multimessenger} astronomy would require an arduous and time-consuming technical process that, thanks to the VO, is fast and transparent to the user. This, aided by the data mining and analysis tools provided by the VO, is what we know as VO-science. Figure \ref{fig:evo_VO} illustrates the significant adoption of VO-science by the astronomical community at an international level, with an increasing trend over the last few years in the use of the developed tools.

Among the plethora of astronomical archives available to the astronomical community, during this thesis we have made extensive use of two of them in particular. J-PLUS is a multi-filter survey conducted from the Observatorio Astrofísico de Javalambre \citep[OAJ;][]{OAJ} in Teruel, Spain, using the 0.83 m Javalambre Auxiliary Survey Telescope (JAST80). All data available in the J-PLUS archive\,\footnote{\url{https://archive.cefca.es/catalogues/jplus-dr3}} is accessible through VO protocols, such as ``Simple Image Access Protocol'', ``Simple Cone Search'', or ``Table Access Protocol''. Especially, we made use of the latter, which allows querying the archive using complex searches based on ADQL\,\footnote{\url{https://www.ivoa.net/documents/REC/ADQL/ADQL-20081030.pdf}}, which is an extension of the common SQL language to support astronomy-specific queries. The wide-field covered by J-PLUS (3\,192\,deg$^2$ in the last data release), combined with its unique system of 12 optical filters \citep{jpluscal} that allows an accurate estimation of stellar parameters such as the effective temperature, provide a suitable setting for the identification on ultracool dwarfs. The CARMENES instrument is installed at the 3.5\,m telescope at the Calar Alto Observatory, located in Almería, Spain, and stands as one of the leading instruments in the quest for searching for Earth-like planets within the habitable zones around M dwarfs using the radial velocity technique. It comprises two separate spectrographs: one for the visible (VIS) wavelength range (from 520 to 960\,nm) and the other for the near-infrared (NIR) range (from 960 to 1710\,nm), each offering high-spectral resolutions of R\,$\approx$\,94\,600 and 80\,500, respectively \citep{Quirrenbach20,reiners2018}. The high-S/N, high-resolution spectra provided by the CARMENES data archive\,\footnote{\url{http://carmenes.cab.inta-csic.es/gto/}}, which is part of the SVO, offer a unique opportunity to determine the photospheric stellar parameters of the observed M dwarfs.

The VO represents a transformative milestone in astronomical research. By breaking down barriers to data access and fostering interoperability between astronomical archives around the world, it has become a cornerstone of modern observational astronomy. As the era of exabyte-scale\,\footnote{$1$\,exabyte $ = 1\,073\,741\,824$\,gigabytes} archives approaches, the continued evolution of VO solutions and protocols will be essential to ensure that astronomy remains at the forefront of scientific discovery in the 21st century. In this sense, the development of science platforms that allow the user to bring the analysis to the data, and not the other way around, will be crucial for scientific analysis on massive amounts of data.  As such platforms are gaining prominence in recent years (e.g. ESA Datalabs\,\footnote{\url{https://datalabs.esa.int/}}), the VO is working on integrating its technologies and protocols into them.

The revolution in data management and accessibility of the last decades did not come alone. The unprecedented scale and complexity of these datasets raised new challenges, as traditional approaches struggle to efficiently process, classify, and extract knowledge from them. This has led to the increasing adoption of artificial intelligence and machine learning, which provide scalable and automated solutions for data analysis, capable of analysing huge amounts of data in an efficient way. From detecting rare astronomical phenomena to refining stellar classifications, artificial intelligence was here to stay.



%-------------------------------------------------------------------

\section{The age of artificial intelligence} \label{chp:ml_intro}


``Can machines think?''. Six years passed from Turing's famous enquiry \citep{turing} until artificial intelligence was consolidated as a research field in the Dartmouth Summer Research Project on Artificial Intelligence conference in 1956, whose organiser, John McCarthy, coined the term ``artificial intelligence'' for the field \citep{McCarthy2006}. Already in 1943, \citet{mcculloh1943} had proposed the first computational model of a biological neuron. In the nearly 80 years since then, artificial intelligence has undergone a remarkable transformation, moving from theoretical explorations to real-world applications that have redefined entire fields, and we have even come to normalise coming across driverless taxis \citep{auto_driving} on the streets of San Francisco and having human conversations with large language models \citep{bubeck2023,deepseek}. Do machines think? Can machines be conscious? These questions has been at the centre of debates in recent years and depend heavily on how we define intelligence and consciousness. For a captivating discussion on this topic, we refer the reader to \citet{qin2025}. What is clear is that, nowadays, machines have the ability to accomplish very complex goals, and this can be of great help to us in building data-driven solutions that ensure that we do not miss out or delay scientific knowledge simply because we cannot cope with the vast amounts of data.

Artificial intelligence, broadly defined as the field focused on the development of machines that mimic human intelligence to solve problems, is a domain that encompasses the well-known subfields of machine and deep learning. While machine learning refers to all systems that automatically learn from the data and make predictions without being explicitly programmed to do so, deep learning focuses on multi-layered neural networks that automatically extract features and create a hierarchical representation of the data. In traditional machine learning, an essential step is feature engineering, where domain experts manually select or design the most relevant features from raw data to improve model performance. For example, in the classification of stellar spectra, an astronomer might compute spectral indices such as the TiO and VO band strengths to distinguish between different M dwarf spectral types. These indices serve as handcrafted features that are then used by machine learning models like support vector machines or decision trees. In contrast, deep learning models, particularly convolutional neural networks, automatically extract relevant features from raw data without requiring manual input. For instance, instead of relying on predefined spectral indices, a convolutional neural network trained on stellar spectra is capable of learning patterns directly from the full spectrum, identifying subtle absorption lines and continuum variations that may be difficult to define explicitly. This automatic feature extraction can enhance classification accuracy and reveal new insights that might be overlooked with traditional methods.

Depending on the nature of the problem to be addressed, machine learning algorithms fall into different categories. Supervised algorithms such as support vector machines \citep{qu2003,huertas2008,kovacs2015,paschenko2018} or supervised decision trees and random forests \citep{carliles2010,moller2016,ishida2019,bluck2022},  are used to map a set of features to a target variable based on input-output pairs that are often based on domain expertise. On the other hand, unsupervised machine learning algorithms such as K-means \citep{balazs2996,sanchez2010,garcia2018}, hierarchical clustering \citep{hojnacki2007,baron2015,ma2018}, principal component analysis \citep{boroson1992,vandenberk2006,bailey2012}, or self-organising maps \citep{meusinger2012,armstrong2016,rahmani2018}, are used to learn complex relationships within an unlabelled dataset for data exploration and visualisation, dimensionality reduction, or outlier detection tasks. It is important to note that several algorithms, such as random forests or artificial neural networks, can be used in both a supervised and unsupervised setting. When a small set of labelled data is available, semi-supervised learning techniques allow leveraging unlabelled data to learn a structured representation of the data or create pseudo-labels \citep{richards2011,Slijepcevic2022}. Alternatively, self-supervised learning algorithms use large amounts of unlabelled data to supervise themselves, and have been wildly used in representation learning \citep[introduced in astronomy by ][]{serra1993}, where algorithms extract meaningful compressed representations (embeddings) of complex high-dimensional data,  during recent years \citep{Yang2015,hayat2021,sarmiento2021,masbuitrago2024}. Reinforcement learning is an active branch of machine learning that optimises control tasks by interacting with a dynamic environment, evaluating outcomes and refining the actions of the system based on long-term rewards, and holds great promise as an approach for adaptive optics in astronomy \citep{Nousiainen2021,nousiainen2022,gutierrez2024}.

The last few years have witnessed an explosion in the number of deep learning methodologies (see Figure \ref{fig:evo}), driven by major advances in the field since the refinement of training techniques for deep neural networks \citep{bengio2006,hinton2006a,hinton2006b} and the popularisation of convolutional neural networks \citep{alexnet2012,vggnet2014}, and also aided by the increase in computational power and the availability of massive datasets. However, machine learning made its debut in astronomy in the late 1980s \citep[see][and references therein]{miller1993}, with artificial neural networks being the core of applications to star-galaxy classification \citep{odewahn1992,odewahn1993,bertin1996,bazell1998,anderson2000,qin2003}, galaxy morphology classification \citep{storrie1992,lahav1995,lahav1996,odewahn1996,cohen2003,madgwick2003}, photometric redshift estimation \citep{firth2003,tagliaferri2003,ball2004}, characterisation of stellar spectra \citep{klusch1993,hippel1994,bailer_jones1997}, quasar classification \citep{carballo2004,claeskens2006}, or cosmology \citep{auld2007,auld2008}. Moreover, in the early 2000s, decision trees and support vector machines began being used for galaxy morphology classification \citep{huertas2008,huertas2011}, photometric redshift estimation \citep{wadadekar2005}, or AGN/galaxy separation \citep{white2000,gao2008}. Within the SVO framework, the first studies using machine learning techniques emerged in the late 2000s, focusing on the automated supervised classification of eclipsing binary light curves \citep{sarro2006}, exoplanet light curves \citep{sarro2006b}, and variable star light curves \citep{debosscher2007,sarro2009}. This was followed by an important contribution to the use of machine learning techniques for the determination of physical parameters of ultracool dwarfs in the scope of the \textit{Gaia} mission \citep{sarro2013,bailerjones2013}. We refer the reader to \citet{ml_review_baron,ml_review_ball,huertas2023,smith2023} for a complete and extensive review of machine and deep learning techniques applied to astronomy.

Deep learning represents a new approach to data analysis in astronomy and in science in general, as it enables the development of unsupervised and self-supervised fully data-driven solutions that do not rely on laborious manual feature engineering or labelling. The simplest artificial neural network is the perceptron, originally introduced by \citep{rosenblatt1958}, which is equivalent to a single neuron node. This node consists of a set of numeric inputs $\textit{x}_{\mathrm{i}}$, which are multiplied by weights $\textit{w}_{\mathrm{i}}$ that represent the strength of the connection between each of the inputs and the neuron. The perceptron then sums the list of products, adds a bias term $\textit{b}$, which allows to the activation function to be shifted linearly, and passes the result to an activation function $\textit{f}$, which gives the final output $\textit{y}$:

\begin{equation}
    \textit{y} = \textit{f}\left ( \sum_{i=1}^{n} \textit{w}_i\textit{x}_i + \textit{b} \right ).
    \label{eq:perceptron}
\end{equation}


Feed-forward artificial neural networks, or multilayer perceptrons, are fully-connected multilayer stacks of individual nodes (see Figure \ref{fig:ann}) that compute non-linear input-output mappings. At each layer, the input of each individual node is obtained as a weighted sum of the outputs of the nodes of the previous layer, and passed to a non-linear activation function in a process known as forward pass (see Figure \ref{fig:ann_activation}). Typically, the rectified linear unit \citep[ReLU; ][]{nair2010}, $\textit{f}(\textit{x})=\max(\textit{x},0)$, is used as non-linear activation function due to its good scalability for networks with many layers and its ability to avoid vanishing gradients \citep{hochreiter1991}. In the training of the network, this forward pass is performed across all layers to compute the prediction of the neural network, which is passed to a loss function that computes the difference between this prediction and the ground truth, or expected output. Then, the gradient of the loss function with respect to the weights of the network is computed using the backpropagation procedure \citep{werbos1974,parker1985,lecun1985,rumelhart1986}, which propagates the gradients backwards from the last layer using the chain rule. Finally, the weights of the network are updated using gradient descent to minimise the loss function \textit{L}:

\begin{equation}
     \textit{w}_{i+1} = \textit{w}_i - \eta \frac{\partial \textit{L}}{\partial \textit{w}_i},
    \label{eq:backpropagation}
\end{equation}

where $\eta$ is the learning rate, which controls how much the weights change. This process is repeated iteratively over multiple epochs, often using optimisation algorithms such as Adam \citep{adam}, until the network reaches a low enough loss.


Inspired by the hierarchical structure of the human visual nervous system \citep[a precursor of convolutional neural networks; ][]{necognitron1980}, convolutional neural networks are a specific class of multilayered feedforward neural networks, initially developed for image classification and visual pattern recognition \citep{lecun1989,lecun1998}. The distinctive factor of convolutional neural networks is the use of convolution operations, in the convolutional layers, to automatically extract features from data. After the convolutional structure, the set of features is flattened and passed to a multilayer perceptron to predict the output of the layer. In each forward pass process, the input of each unit of the convolutional layer is obtained with an element-wise dot product between a set of weights known as convolution kernel or filter, and the output feature maps of the previous layer (see Figure \ref{fig:cnn_intro}). In a same layer, different units use different filters. The resulting arrays and a tunable bias are added up and passed through an activation function to obtain the output feature map of each unit. The set of weights of each kernel and the weights of the multilayer perceptron are adjusted in the training process, so that the different feature maps of the convolutional layers represent specific features detected in the input data\,\footnote{We refer the interested reader to \url{https://poloclub.github.io/cnn-explainer/} for an interactive visualisation of the internal workings of a convolutional neural network.}. This feature representation learnt by the network is hierarchical, preserving the generic learning in the lower layers (closer to the input) and the more specific features in the higher layers.

The deep learning explosion started in 2012. In the ImageNet Large Scale Visual Recognition Challenge competition \citep{russakovsky2014} of this year, a deep convolutional neural network called AlexNet \citep{alexnet2012} achieved incredible results, far outperforming its competitors\,\footnote{According to The Economist, ``Suddenly people started to pay attention, not just within the artificial intelligence community but across the technology industry as a whole.''.} thanks to the use of graphics processing units, ReLU activation functions, data augmentation, and a technique know as dropout that prevents the network from overfitting \citep{dropout}. This success initiated a revolution in the field of computer vision, and the pace of improvement in the following years of the ImageNet competition was dramatic \citep{vggnet2014,googlenet,resnet}. It did not take astronomers long to notice. Due to their nature, it is not surprising that early work using convolutional neural networks in astronomy focused on image classification, for pulsar identification \citep{zhu2014} and for galaxy morphological classification \citep{dieleman2015,huertas2015,aniyan2017}. Moreover, \citet{hala2014} pioneered the use of convolutional neural networks for spectral classification. These works signalled the beginning of the use of deep learning techniques in astrophysics, which has been growing at an overwhelming rate ever since.


As discussed in Section \ref{chp:vo_intro}, astronomical datasets are becoming increasingly large and complex, making the exploration of these archives almost impossible without the use of data discovery techniques. In this sense, machine learning has emerged as a powerful tool for visualising or detecting anomalies in vast datasets. Data visualisation is essential for the exploration of high-dimensional astronomical datasets, bringing the data to a lower dimensionality that allows it to be analysed in a more interpretable way. Dimensionality reduction techniques, such as principal component analysis \citep{hotelling:33}, t-SNE \citep{vandermaaten08}, UMAP \citep{McInnes2018}, or self-organising maps \citep[Kohonen networks; ][]{kohonen1982}, are widely used in this regard. Moreover, unsupervised and self-supervised representation deep learning, especially using autoencoder architectures \citep{serra1993} and more recently contrastive learning models \citep{chen2020}, are used to extract meaningful embeddings from high-dimensional astronomical data, that can be used as input for a downstream classification or regression task. These methodologies constitute also a vital tool for the detection of anomalies or outliers in big data surveys \citep{chalapathy2019}, which enables the discovery of rare or unexpected phenomena within massive datasets, where the combination of deep learning methods with the VO technology is extremely useful \citep{skoda2020}. Moreover, VO solutions are very helpful in further characterising these anomalous instances detected in surveys. This is particularly important for the field of transient astronomy, that will soon experience a revolution with the forthcoming LSST survey \citep{li2022} of the Vera C. Rubin Observatory.

The dependence of deep learning algorithms on massive training data is a crucial hurdle to overcome when a research scenario requires labelled data, as building a large annotated dataset can be incredibly complex and expensive. This is the case, for example, when a classification or regression task is to be performed on a small labelled sample. A straightforward, and widely used in astronomy, solution to this problem is the use of a data-rich labelled dataset similar to the target dataset or of synthetic data to train the deep learning models, but this may include a systematic error in the methodology if the training set is not identical to the observed data on which the inference is made \citep{pass20}. Transfer learning, in which knowledge is transferred from a rich source domain to a related but not identical target domain, plays a key role in solving the above problems. Knowledge transfer is typically performed by training a deep learning model on a data-rich dataset and then fine-tuning the neural network weights using the target dataset \citep{dominguez2018,walmsley2022,bello2023,masbuitrago2024}. Another approach to this problem is the use of active learning \citep{walmsley2020,stevens2021}, which reduces the number of required training samples by selecting the most informative data to label. For the simulation of data-rich labelled datasets, deep generative models (introduced in astronomy by \citealt{regier2015}) such as variational autoencoders, generative adversarial networks, score-based generative models, or diffusion models, can be leveraged to generate massive amounts of data similar to astronomical observations. Deep generative models enable data-driven simulation as they capture the underlying probability distribution of a given dataset, and use that knowledge to generate new, realistic synthetic data from it.

With the captivating title ``Attention is All You Need'', \citet{vaswani2017} presented the revolutionary transformer neural network, based on a mechanism known as attention that computes the relevance of each input token with respect to all others in a sequence and captures contextual relationships, and which is still largely unexploited in astronomy \citep{astromer,atat}. Transformer architectures are the pillars on which large language models, such as PaLM \citep{palm}, LLaMa \citep{llama}, or GPT-4 \citep{gpt4} are built, which have revolutionised the field of natural language processing in the last two years. Thanks to their versatility and their ability to handle multimodal data \citep{reed2022}, transformers can be harnessed to build what we know as foundation models, which are models that are trained on vast amounts of data using self-supervised learning for subsequent fine-tuning tailored to diverse specific downstream tasks. Interest in foundation models in astronomy is growing rapidly \citep{astrollama,rozanski2023,leung2024,parker2024}, since the natural evolution for the upcoming decades would be a transition from domain-specific deep learning models to fine-tuned versions of the same all-encompassing astronomical foundation model. The miscellaneous and rich nature of astronomical data generated from entirely different instruments, combined with the interoperability enabled by VO technology, represents a key opportunity in this regard. To this end, it is paramount that the astronomical community adopts a transparent, open-source, bazaar-style development, which has proven successful in large open-source projects such as Linux \citep{raymond2001}, with a strong commitment to interpretability (see \citet{ras2020} for a detailed discussion on explainable artificial intelligence). This open and democratised scenario would unlock the potential of state-of-the-art deep learning solutions for the entire astronomical community, solving the current inaccessibility of most astronomers to these models due to lack of resources.

The characterisation of M dwarfs and ultracool dwarfs is fundamental to advancing our understanding of stellar astrophysics, planetary formation and habitability, and the structure and kinematics of our Galaxy, yet their characterisation remains an ongoing challenge due to their intrinsic faintness and complex atmospheres. As astronomical datasets grow in size and complexity, the ability to efficiently mine and analyse these vast archives has become a necessity, with the VO playing a key role in enabling multi-wavelength data discovery and interoperability. In parallel, the rise of machine and deep learning has transformed how we extract knowledge from astronomical data at an unprecedented scale, offering new approaches for classification, parameter estimation, anomaly detection, and data-driven discovery. The synergy between VO technologies and machine learning has set the stage for a new era in astronomical research, one in which automated, scalable, and interpretable solutions will be essential for maximising the scientific return of upcoming large-scale surveys. Recent applications of machine and deep learning in astronomy, as exemplified above, illustrate how artificial intelligence is not only optimising data analysis but also driving new discoveries that would otherwise be unfeasible with traditional methods. The fusion of artificial intelligence and astronomy is no longer just an option--it is a necessity.

%--------------------------------------------------------------------

\section{Aims and objectives of the thesis} \label{sec:thesis_obj}


The aim of this thesis is to explore the application of machine learning and deep learning techniques to spectroscopic and photometric surveys, with a particular focus on M dwarfs and ultracool dwarfs, demonstrating how these methodologies can enhance our understanding of low-mass stars and substellar objects, and push the boundaries of data-driven astronomical research. The thesis can be divided into two main objectives. The first, covered in Chapter \ref{chp:ucds_paper}, is to consolidate a methodology for identifying ultracool dwarfs in wide-field multi-filter photometric surveys, using data from the J-PLUS survey, driven by VO data mining techniques and tools. In view of the vast surveys with these characteristics that will come to light in the very near future, this thesis aims to demonstrate that a machine learning approach is able to significantly accelerate this process. A sub-objective derived from this first one is to leverage these surveys for the automatic detection of flares in M dwarfs (Chapter \ref{chp:flares_paper}), thanks to specific narrow-band filters located at specific spectral features. The second objective, which encompasses Chapters \ref{chp:autoencoders_paper} and \ref{chp:dtl_ucds}, is to develop an automatic and scalable deep learning-based methodology capable of determining the atmospheric parameters of M dwarfs and ultracool dwarfs from spectroscopic data. The strategy here starts with the use of M dwarf high-resolution spectra from CARMENES, and the subsequent adaptation to the ultracool domain is carried out with low-resolution spectra from the SpeX Prism Library.

%************************************************
\chapter{Ultracool Dwarfs in J-PLUS}
\label{chp:ucds_paper}



%************************************************


Ultracool dwarfs (UCDs) comprise the lowest mass members of the stellar population and brown dwarfs, from M7\,V to cooler objects with L, T, and Y spectral types. Most of them have been discovered using wide-field imaging surveys, for which the Virtual Observatory (VO) has proven to be of great utility. We aim to perform a search for UCDs in the entire Javalambre Photometric Local Universe Survey (J-PLUS) second data release (2\,176\,deg$^2$) following a VO methodology. We also explore the ability to reproduce this search with a purely machine learning (ML)-based methodology that relies solely on J-PLUS photometry. We followed three different approaches based on parallaxes, proper motions, and colours, respectively, using the \texttt{VOSA} tool to estimate the effective temperatures and complement J-PLUS photometry with other catalogues in the optical and infrared. For the ML methodology, we built a two-step method based on principal component analysis and support vector machine algorithms. We identified a total of 7\,827 new candidate UCDs, which represents an increase of about 135\,\% in the number of UCDs reported in the sky coverage of the J-PLUS second data release. Among the candidate UCDs, we found 122 possible unresolved binary systems, 78 wide multiple systems, and 48 objects with a high Bayesian probability of belonging to a young association. We also identified four objects with strong excess in the filter corresponding to the Ca~{\sc ii} H and K emission lines and four other objects with excess emission in the H$\alpha$ filter. Follow-up spectroscopic observations of two of them indicate they are normal late-M dwarfs. With the ML approach, we obtained a recall score of 92\,\% and 91\,\% in the  20$\times$20\,deg$^2$ regions used for testing and blind testing, respectively. We consolidated the proposed search methodology for UCDs, which will be used in deeper and larger upcoming surveys such as J-PAS and Euclid. We concluded that the ML methodology is more efficient in the sense that it allows for a larger number of true negatives to be discarded prior to analysis with \texttt{VOSA}, although it is more photometrically restrictive.


%--------------------------------------------------------------------

\section{J-PLUS} \label{jplus_intro}

J-PLUS is a multi-filter survey conducted from the Observatorio Astrofísico de Javalambre \citep[OAJ;][]{OAJ} in Teruel, Spain. Since it was primarily conceived to ensure the photometric calibration of J-PAS, it uses the second largest telescope at the OAJ, which is the 0.83 m Javalambre Auxiliary Survey Telescope (JAST80). J-PLUS is covering thousands of square degrees of the sky using the panoramic wide-field (2\,deg$^2$ field of view) camera T80Cam \citep{t80cam}, which is equipped with a CCD of 9.2k x 9.2k pixels and a pixel scale of 0.55\,arcsec\,pix$^{-1}$.

While J-PAS will use an unprecedented system of 56 narrow band filters in the optical, the J-PLUS filter system is composed of four broad  (\textit{gSDSS}, \textit{rSDSS}, \textit{iSDSS}, and \textit{zSDSS}), two intermediate (\textit{uJAVA} and \textit{J0861}) and six narrow (\textit{J0378}, \textit{J0395}, \textit{J0410}, \textit{J0430}, \textit{J0515}, and \textit{J0660}) band optical filters. The transmission curves, as well as additional information of these filters, can be found at the \textit{Carlos Rodrigo} Filter Profile Service maintained by the Spanish Virtual Observatory\,\footnote{\url{http://svo2.cab.inta-csic.es/theory/fps/index.php?&mode=browse&gname=OAJ&gname2=JPLUS}} \citep{fps}.

The J-PLUS DR2, available since November 2020, comprises 1\,088 fields, covering 2\,176\,deg$^2$, observed in all the mentioned optical bands. Fig. \ref{fig:mocs} shows the sky coverage of this release. \citet{jpluscal} presents the updated photometric calibration for the DR2, that was improved by including the metallicity information from LAMOST DR5 in the stellar locus estimation. The limiting magnitudes of the 12 bands can be consulted in the Table 1 of the same paper.

%--------------------------------------------------------------------

\section{Methodology} \label{Methodology}



We divided the sky coverage of J-PLUS DR2 in 37 regions of 20$\times$20\,deg$^2$. To cope with the fact that queries to the J-PLUS archive are limited to 1 million objects, we decided to tessellate each region into smaller circular subregions of 1 deg radius. We made use of \texttt{TOPCAT}\footnote{\url{http://www.star.bris.ac.uk/~mbt/topcat/}} \citep{Taylor2005} to cross-match each tessellated region with the J-PLUS DR2 sky coverage in order to avoid searching regions of the sky that are not covered by it.


We used the package \texttt{STILTS}\footnote{\url{http://www.star.bris.ac.uk/~mbt/stilts/}} \citep{Taylor2006} to query the J-PLUS DR2 database through the Virtual Observatory TAP protocol. This allowed us to write ADQL\footnote{\url{https://www.ivoa.net/documents/REC/ADQL/ADQL-20081030.pdf}} code to search over all 20$\times$20\,deg$^2$ regions iteratively. A typical ADQL query example looks like this:

\newpage

\begin{code}
SELECT objs.filter_id,objs.alpha_j2000,
    objs.delta_j2000,objs.class_star,
    objs.mag_aper_6_0,objs.mag_err_aper_6_0,
    objs.mask_flags,imgs.aper_cor_6_0,
    imgs.aper_cor_err_6_0
FROM jplus.MagABSingleObj as objs,
    jplus.TileImage as imgs
WHERE objs.tile_id = imgs.tile_id
AND objs.alpha_j2000 between 2 and 5
AND objs.delta_j2000 between 2 and 3
AND objs.flags=0
AND objs.filter_id between 1 and 4
AND objs.class_star>0.1
\end{code}

In our case, we used the 6 arcsec diameter aperture photometry, since the aperture correction to pass 6 arcsec aperture magnitudes to total magnitudes for point-like sources is available in the J-PLUS DR2 database. We constrained the search to records with good photometric conditions by imposing  \texttt{flags=0} (no \texttt{SExtractor} flags\footnote{\url{https://sextractor.readthedocs.io/en/latest/Flagging.html}}). Since object detection is performed independently on each filter, this means that for each source the \texttt{flags=0} condition is applied at the filter level. We also required \texttt{class$\_$star > 0.1}. We were not very restrictive with \texttt{class$\_$star} (\texttt{SExtractor} stellarity index) in order not to loose faint sources that may appear as extended objects.

For each 20$\times$20\,deg$^2$ region, we concatenated the data for the corresponding circular subregions into a single table and removed duplicated instances (tessellated areas may overlap). As UCDs emit most of their flux at longer wavelengths, for the methodology described in Sects. \ref{parallax}, \ref{pm} and \ref{colordiagram}, we only considered the relevant filters for these objects, i.e., the reddest ones (filter IDs 1$-$4 and 10$-$12 in the J-PLUS DR2 database, see Table \ref{tab:filters}). Even so, we stored the data for all filters separately, as we required them for the flare detection workflow described in Sect. \ref{flares}. Finally, we used the CDS \texttt{X-Match} service\footnote{\url{http://cdsxmatch.u-strasbg.fr/}} in \texttt{TOPCAT} with \textit{Gaia} EDR3 J2016 (reference epoch 2016.0), using a 3 arcsec radius, to obtain the astrometric information. In those cases where more than one counterpart exists in the search region, only the nearest one was considered. In Sects. \ref{parallax}, \ref{pm} and \ref{colordiagram} we describe the analysis carried out for each 20$\times$20\,deg$^2$ region separately.


\subsection{Parallax-based selection} \label{parallax}

From the cross-matched sample, we only kept sources with relative errors of less than 20\,\% in parallax and less than 10\,\% in both \textit{G} and $\textit{G}_{\rm RP}$ photometry. With these objects, we constructed a colour-magnitude diagram (see the left panel of Fig. \ref{fig:astro_diagrams}), where the absolute \textit{Gaia} magnitude in the \textit{G} band was estimated using

\begin{equation}
    M_G= \textit{G} + 5\log{\varpi} + 5,
	\label{eq:absoluteg}
\end{equation}

\noindent where \textit{G} is the \textit{Gaia} apparent magnitude and $\varpi$ is the parallax in arcseconds. To obtain a shortlist of candidate UCDs, we adopted a colour cut of $\textit{G} - \textit{G}_{\rm RP} > 1.3$\,mag, which corresponds to spectral types M5\,V or later according to the updated version of Table 5 in \citet{pecaut2013} \footnote{\label{mamajek}\url{http://www.pas.rochester.edu/~emamajek/EEM_dwarf_UBVIJHK_colors_Teff.txt}}, and an absolute magnitude limit of $M_G > 5$\,mag to leave aside the red giant branch.


\subsection{Proper motion-based selection} \label{pm}

Ultracool dwarfs may have photometric and morphological properties similar to those of objects such as giants, quasi-stellar objects (QSOs) or distant luminous red galaxies \citep[e.g.][]{Caballero2018, theissen2016, theyssen2017}. Assuming nearby objects will have high proper motions, reduced proper motion diagrams are a reliable tool for discriminating between nearby stellar populations and distant sources.

From the cross-matched sample introduced in Sect. \ref{Methodology}, we only kept sources with a relative error of less than 20\,\% in both proper motion components and less than 10\,\% in both \textit{G} and $\textit{G}_{\rm RP}$ photometry. Furthermore, we only took into account sources with non-zero proper motion, i.e., sources with, at least, one of the proper motion components greater (in absolute value) than three times the associated error.

The right panel of Fig. \ref{fig:astro_diagrams} shows the reduced proper motion diagram defined as:

\begin{equation}
    H_G=\textit{G} + 5\log{\mu} + 5,
	\label{eq:reducedpm}
\end{equation}

\noindent where \textit{G} is the \textit{Gaia} apparent magnitude and $\mu$ is the total proper motion in mas\,yr$^{-1}$. Of these sources, we filtered out those already pre-selected in the parallax-guided analysis described in Sect. \ref{parallax} and shortlisted as candidate UCDs those fulfilling the condition $\textit{G} - \textit{G}_{\rm RP} > 1.3$\,mag, and with a reduced proper motion $H_G > 22$\,mag to leave aside the red giant branch.

As discussed in Sect. \ref{Methodology}, the cross-match with \textit{Gaia} EDR3 J2016 is done using a 3 arcsec radius. Since J-PLUS DR2 is based on images collected from November 2015 to February 2020, we might miss some objects with a proper motion larger than 750\,mas\,yr$^{-1}$, as they could fall outside this 3\,arcsec radius. However, we decided not to increase the radius to avoid finding erroneous counterparts.

\subsection{Photometry-based selection} \label{colordiagram}


In the first two criteria (colour-magnitude and reduced proper motion diagrams) we are imposing parallax and proper motion constraints respectively, which makes these methods dependent on \textit{Gaia} astrometric information. This means that objects with good photometry but poor astrometry will be excluded from the lists of candidate UCDs. To solve this limitation, in this section we describe a method solely dependent on photometric information. This procedure consisted of two separate steps. First, we built a colour-colour diagram with the purpose of defining a colour cut to identify the UCD locus. Then, we applied this criterion to each 20$\times$20\,deg$^2$ region independently to obtain a shortlist of candidate UCDs.

To built the colour-colour diagram, we first searched in J-PLUS DR2 for true extended sources, defined as sources having \texttt{class$\_$star < 0.01}. Likewise, true point sources were defined as sources with \texttt{class$\_$star > 0.99}. Then, we performed a cross-match with 2MASS and built a $\textit{J}-\textit{K}_s$ (2MASS) vs. $\textit{r}-\textit{z}$ colour-colour diagram to separate the two types of sources.  As discussed in Sect. \ref{pm}, QSOs may have morphometric properties similar to those of UCDs, so it is crucial to also discriminate between these two types in the colour-colour diagram.

Fig. \ref{fig:colour} shows the different types of objects in a colour-colour diagram. For the sample of QSOs, we cross-matched the SDSS-DR12 Quasar Catalog\footnote{\url{http://cdsarc.u-strasbg.fr/viz-bin/cat/VII/279}} with the J-PLUS DR2. To define the UCD locus, we overplotted in this diagram the candidate UCDs obtained by the methods described in Sects. \ref{parallax} and \ref{pm} for the region $\alpha$: 0 -- 20\,deg; $\delta$: 0 -- 20\,deg. As a compromise to balance the extended object contamination and the loss of candidate UCDs, we defined the UCD locus as the region fulfilling $\textit{r}-\textit{z} > 2.2$\,mag and applied this criterion to all the sources of each 20x20 deg$^2$ region. Of the sources fulfilling it, we filtered out those already pre-selected in the analysis described in Sects. \ref{parallax} and \ref{pm} and shortlisted the remaining ones as candidate UCDs.


\subsection{VOSA filtering} \label{vosa}

To estimate physical properties, such as effective temperature, luminosity or radius of the shortlisted objects described in the previous sections, we made use of the tool \texttt{VOSA}\footnote{\url{http://svo2.cab.inta-csic.es/theory/vosa/}} \citep{vosa}. This is a tool developed and maintained by the Spanish Virtual Observatory\footnote{\url{https://svo.cab.inta-csic.es}} which fits observational data to different collections of theoretical models. An example of \texttt{VOSA} Spectral Energy Distribution (SED) fitting can be found in Fig. \ref{fig:vosa_sed}. Before doing the fit, we built the observational SEDs using the J-PLUS photometric information as well as additional photometry from the 2MASS, UKIDSS, WISE, and VISTA infrared surveys, and from the SDSS data release 12 optical catalogue, available in \texttt{VOSA}.


In our analysis, we used the BT-Settl (CIFIST) collection of theoretical models \citep{allard2012, caffau2011}. Thus, the effective temperature estimated by \texttt{VOSA} is discretised due to the step adopted in the CIFITS grid of models (100\,K). We also assumed a surface gravity logg in the range 4.5 to 5.5 and solar metallicity. The limiting magnitude (5$\sigma$, 3\,arcsec diameter aperture) of J-PLUS DR2 is 20.5 [AB] in the \textit{z} band \citep{jpluscal}. If we take, for example, the object TVLM 891-15871, which is one of the objects in the UCD catalogue presented in \citet{Reyle2018} with the brightest absolute magnitude (11.36 [AB]) in the \textit{z} band, we see that it could be detected at a maximum distance of $\sim$680\,pc. This leads us to expect a maximum distance of about 650-700\,pc to find UCDs in the J-PLUS DR2.

Extinction plays a fundamental role in shaping the SED and, therefore, in the estimation of physical parameters \citep{extinction_laugalys, extinction_straizys}. Considering the maximum distance at which UCDs can be detected with J-PLUS, we adopted a range of values between $A_V=0$\,mag and $0.5$\,mag. We relied on the calibration described in Table 1 of \citet{solano2021} to adopt a temperature cutoff of 2\,900\,K for UCDs if the BT-Settl (CIFIST) models are used in \texttt{VOSA}. The goodness of fit of the SED in \texttt{VOSA} can be assessed with the vgfb parameter, a pseudo-reduced $\chi^2$ internally used by \texttt{VOSA} that is calculated by forcing $\sigma(F_{\rm obs}) > 0.1\times F_{\rm obs}$, where $\sigma(F_{\rm obs})$ is the error in the observed flux ($F_{\rm obs}$). Only sources with good SED fitting (vgfb < 12) were kept.

After applying these effective temperature and vgfb conditions, we used \texttt{TOPCAT} to remove the objects with a non-zero confusion flag (\texttt{cc\_flg}) in 2MASS, so as to ensure that objects are not contaminated or biased due to the proximity to a nearby source of equal or greater brightness. Moreover, we used the \texttt{Aladin} sky atlas \citep{aladin} to carry out a visual inspection of the coldest objects, in order to discard any problem related to blending or contamination by nearby objects. Finally, we ended up with 9\,810 final candidate UCDs. For the record, we checked that 204 of these objects have a renormalised unit weight error \citep[RUWE; ][]{lindegren2018} greater than 1.4 in \textit{Gaia} EDR3, which could mean that the source is affected by close binary companions. These objects were not removed since a binarity analysis is performed in Sect. \ref{binarity}.

As we use multiple detection methods in our methodology, distinct candidate UCDs may have been detected by different methods, or by several of them. Fig. \ref{fig:methods_both} shows the breakdown of the 9\,810 candidate UCDs according to the methods by which they have been detected. The fact that 2\,100 objects are only detected by the photometric methodology (`diag' bar in Fig. \ref{fig:methods_both}) and 4\,530 are only detected by the astrometric methodology (`par', `pm', and `par\&pm' bars in Fig. \ref{fig:methods_both}) argues for the complementary nature of both approaches. Considering each method separately, we detected 6\,086 candidates with parallax-based selection, 6\,338 with proper motion-based selection, and 5\,280 with photometry-based selection.

%--------------------------------------------------------------------

\section{Analysis} \label{Analysis}

\subsection{Temperatures and distances} \label{dist_temps}

Fig. \ref{fig:temphist} shows that the distribution of effective temperatures for our candidate UCDs is not the same depending on whether they have been detected by astrometric methodology (blue) or not. To prove this, we performed a two-sample Kolgomorov-Smirnov test on the two samples, which returned a $p$ value = 3.66\,$\cdot\,10^{-15}$, rejecting the possibility that both samples are coming from the exact same distribution. The number of cold objects ($T_{\rm eff}\leq$ 2\,200\,K) is clearly higher in the only-photometry detected distribution (yellow). Most of our candidates ($\sim$86\,\%) have $T_{\rm eff}\geq$ 2\,700\,K, a clear consequence of the working wavelength, since UCDs peak in the near-infared, and J-PLUS covers only up to the z filter ($\lambda_{\rm eff}=8\,940.28$\,\AA).


For the distance distribution of our candidate UCDs (Fig. \ref{fig:disthist}), we only considered the candidates with a relative error of less than 20\,\% in parallax (6\,086 objects), so we can rely on the inverse of the parallax as a distance estimator \citep{Luri2018}. In our case, as mentioned in Sect. \ref{Methodology}, the parallax are those of \textit{Gaia} EDR3. About 70\,\% of the objects lie in the $96 < {\rm D\,(pc)} < 222$ region (1$\sigma$ limits), with a maximum and minimun distance of 471\,pc and 11\,pc, respectively. This upper limit is consistent with the value estimated in Sect. \ref{vosa}. We found 68 nearby objects, at distances smaller than 40\,pc, that will be further discused in Sect. \ref{new_vs_known}. Fig. \ref{fig:temp_lum} gives a more in-depth view of the characteristics of our candidate UCDs. As expected, most of the cooler candidates are detected at closer distances and tend to have lower bolometric luminosity.


\subsection{Kinematics} \label{tangential_vel}

Stellar kinematics is a reliable proxy for segregating large-scale galactic populations (thin disk, thick disk, and halo) \citep{Burgasser2015}. Using \textit{Gaia} EDR3 proper motions and parallaxes, we computed the tangential velocities of our candidate UCDs as $v_{\rm tan}=4.74 \mu d$, where $v_{\rm tan}$ is given in km\,s$^{-1}$, $\mu$ is the total proper motion in arcsec\,yr$^{-1}$ and $d$ is the distance in pc. For a correct estimation of the tangential velocity, we only considered candidates that met both conditions described in Sects. \ref{parallax} and \ref{pm} for good parallax and proper motion (4\,714). Fig. \ref{fig:vtan_hist} shows the distribution of tangential velocities for these candidates, with  a mean value of $v_{\rm tan}=39.78$\,km\,s$^{-1}$, a median value of $v_{\rm tan}=33.99$\,km\,s$^{-1}$, and a dispersion of $\sigma_{\rm tan}=24.85$\,km\,s$^{-1}$. Even taking into account objects located at the long tail of the distribution (134 objects, representing 2.8\,\% of the total, with $v_{\rm tan}>100$\,km\,s$^{-1}$), these values agree with previous calculations for UCDs \citep{faherty2009}.

\citet[][Fig. 10]{Torres2019} shows a breakdown of the tangential velocity based on the membership in the thin disk, the thick disk or the halo. Relying on these values, we can segregate our candidate UCDs into thin disk ($v_{\rm tan}\leq 85$\,km\,s$^{-1}$), thick disk ($85< v_{\rm tan}< 155$\,km\,s$^{-1}$), and halo ($v_{\rm tan}\geq 155$\,km\,s$^{-1}$) populations. We found 4\,441, 268 and five candidate UCDs in these intervals, respectively. According to \citet{Kilic2017}, the corresponding ages are 6.8-7.0\,Gyr (thin disk), 7.4-8.2\,Gyr (thick disk), and 12.5$^{+1.4}_{-3.4}$\,Gyr (halo).


Three of the potential halo members show a very high tangential velocity. Two of them, with Simbad identifiers 2MASS J18030236+7557587 and 2MASS J13155851+2814524, are not far from the thick disk-halo threshold, with tangential velocities of $v_{\rm tan}=176.25$\,km\,s$^{-1}$ and $v_{\rm tan}=177.47$\,km\,s$^{-1}$, respectively. Furthermore, one of the objects has $v_{\rm tan}=206.16$\,km\,s$^{-1}$, which significantly exceeds the limit. This object, at a distance of 179 pc, is reported as an M7 in the catalogue provided by \citet{ahmed2019} with the id J132625.03+333506.7. Due to its high tangential velocity, we conclude this object could be a potential member of the Galactic halo. We used the ($\textit{J}-\textit{K}_{\rm s}$, $\textit{i}-\textit{J}$) colour-colour diagram presented in \citet{lodieu2017} to study the metallicity of this object. With values of $\textit{J}-\textit{K}_{\rm s}=0.77$ and $\textit{i}-\textit{J}=3.29$, the object exhibits subdwarf behaviour (low metallicity). Fig. \ref{fig:vtan_temp} shows the mean and standard deviation of the tangential velocity for each value of the effective temperature. There is no evidence of correlation between effective temperature and tangential velocity among our candidates.

To study the possible membership of our candidate UCDs to nearby young associatons, we relied on \texttt{BANYAN}~$\Sigma$\footnote{\url{http://www.exoplanetes.umontreal.ca/banyan/}} \citep{banyan}, a Bayesian analysis tool to identify members of young associations. Modelled with multivariate Gaussians in six-dimensional $\rm XYZUVW$ space, \texttt{BANYAN}~$\Sigma$ can derive membership probabilities for all known and well-characterised young associations within 150\,pc. As we found no radial velocity data available for any of the 4\,714 candidate UCDs with good parallax and proper motion, we introduced the sky coordinates, proper motion, and parallax of these objects as input parameters to the algorithm.

For 4\,666 of the candidate UCDs, the algorithm predicted that most of them are field stars. However, it gave a high Bayesian probability for 48 objects to belong to a young association, in 30 of the cases with a probability greater than 95\,\%. In more detail, the algorithm mapped 34 candidate UCDs to the Pisces-Eridanus stellar stream \citep{PERI}, five to the Argus Association \citep{argus}, four to the AB Doradus Moving Group \citep{abdmg}, two to the Columba association \citep{columba}, and one each to the Tucana-Horologium \citep{tha}, $\beta$ Pictoris \citep{bpictoris}, and Carina-Near \citep{carn} associations. We verified all these 48 objects have tangential velocities typical of the thin disk, with mean $v_{\rm tan}=16.37$\,km\,s$^{-1}$ and standard deviation $\sigma = 6.17$\,km\,s$^{-1}$. As mentioned in \texttt{BANYAN}~$\Sigma$, a high membership probability in a young association does not guarantee that the star is a true member, or young, so further follow-up would be needed to demonstrate the youth of the object. Moreover, we note that the absence of radial velocity may cause the membership probabilities given by \texttt{BANYAN}~$\Sigma$ to be inflated.

\subsection{Binarity} \label{binarity}

We conducted a search for binary systems among our candidate UCDs in two ways. We searched for unresolved binaries using a methodology based purely on the photometry of our objects. Using the complementary photometry functionality of \texttt{VOSA}, we selected only the candidates fulfilling three conditions. First, with an excess detected by \texttt{VOSA} in any filter in the infrared. We discarded WISE $W3$ and $W4$ due to their poor angular resolution and sensitivity. Second, with good photometry in both 2MASS (\texttt{Qfl} = A) and WISE (\texttt{cc\_flags} = 0 and \texttt{ph\_qual} = A or B). Third, with at least three good photometric points in the infrared, apart from the detected excess.

After applying these conditions, we ended up with 291 objects with an excess in the infrared that could be ascribed to circumstellar material or to the presence of a close ultracool companion. Then, we used the binary fit functionality of \texttt{VOSA} to fit the observed SED of these 291 objects using the linear combination of two theoretical models. After this, we ended up with 122 candidate UCDs for which the infrared excess detected is nicely reproduced by performing a two-body fit, suggesting the existence of an unresolved companion.

In parallel to this, we looked for \textit{Gaia} companions of our candidate UCDs at large angular separations, using only those with reliable parallax and proper motion (4\,714). Firstly, we cross-matched these sources with \textit{Gaia} EDR3 J2016 to get all the objects separated a maximum of 180 arcsec in the sky (maximum separation allowed by the \texttt{X-match} service in \texttt{TOPCAT}) from each of our candidate UCDs. Then, we established a conservative upper limit of 100\,000\,au for the projected physical separation between a candidate and its companion. Finally, we relied on the conditions presented in \citet{smart_dwarfs} to ensure that the companion shares a parallax and proper motion similar to that of our candidate UCD:


\begin{itemize}

    \item $\Delta \varpi < max[1.0, 3\sigma_{\varpi}]$
    \item $\Delta(\mu_{\alpha}\cos{\delta}) < 0.1\mu_{\alpha}\cos{\delta}$
    \item $\Delta \mu_{\delta} < 0.1\mu_{\delta}$

\end{itemize}

\noindent where $\varpi$ and $\mu$ are the parallax and proper motion of our candidate UCDs, respectively. After applying these criteria, we ended up with 73 candidate UCDs with one \textit{Gaia} companion and another five candidate UCDs with two \textit{Gaia} companions identified. Of these 78 objects, six are already tabulated as known binary systems by the Washington Double Star catalogue \citep[WDS;][]{WDS}. Table \ref{tab:binaries} lists the coordinates (J2000), parallaxes, proper motions, angular separations $\rho$ and projected physical separations $s$ of the six known systems. A table with the same information for the identified multiple systems that are not tabulated by the WDS is accesible through the catalogue described in Section \ref{data_av}.

A deeper knowledge of the \textit{Gaia} companion may allow us to infer properties, such as metallicity, of our candidate UCD. We only found spectral types in Simbad for two of the detected companions, with spectral types F2 and K3V. To obtain information about the rest of the companions, we first made use of \texttt{VOSA} to get an estimate of their effective temperature. Then, we relied on the updated version of Table 5 in \citet{pecaut2013} to map these effectives temperatures to the spectral types of the companions. As result, we ended up with four F-type, one G-type, 16 K-type and 42 M-type stars among the companions with good SED fitting in \texttt{VOSA}. For the rest of the companions, we obtained a bad SED fitting in \texttt{VOSA} (vgfb > 12), so we could not get an estimation of the effective temperature.


%--------------------------------------------------------------------

\section{Known ultracool dwarfs} \label{known}

\subsection{Recovered known UCDs} \label{recovered_known}

Here, we assess the number of known UCDs found in the J-PLUS DR2 field and the fraction of them that were recovered using our methodology. For this analysis, we used nine catalogues and services: SIMBAD\footnote{\url{http://simbad.u-strasbg.fr/simbad/}} \citep{Wenger00}, \citet{zhang2009}, \citet{zhang2010}, \citet{schmidt2010}. \citet{skrzypek2016}, \citet{smart2017}, \citet{Reyle2018}, \citet{panstarrs1}, and \citet{ahmed2019}. Using the SIMBAD TAP service\footnote{\url{http://simbad.u-strasbg.fr:80/simbad/sim-tap}} through \texttt{TOPCAT}, we selected objects with spectral types M7\,V, M8\,V, M9\,V or labelled as brown dwarfs. A total of 18\,282 objects were recovered. Also, from \citet{panstarrs1} we chose the 2\,090 objects having spectral type M7 or later. As all the 33\,665, 14\,915, 1\,886, 1\,361, 806, 484 and 129 objects in the \citet{ahmed2019}, \citet{Reyle2018}, \citet{smart2017}, \citet{skrzypek2016}, \citet{zhang2010}, \citet{schmidt2010}, and \citet{zhang2009} catalogues, respectively, are within our scope (spectral type M7 or later), we included them in their entirety.

To select only the known UCDs that lie in the region of the sky covered by J-PLUS DR2 we made use of \texttt{TOPCAT} and its \texttt{nearMOC} functionality, which indicates whether a given sky position either falls within, or is within a certain distance of the edge of, a given MOC. The MOC\footnote{\url{https://www.ivoa.net/documents/MOC/}} (Multi-Order Coverage Map) is an encoding method dedicated to VO applications or data servers which allows to manage and manipulate any region of the sky, defining it by a subset of regular sky tessellation using the HEALPix method \citep{healpix}. Out of a total of 5\,817 objects lying in the J-PLUS DR2 field of view, we ended up with 4\,734 known UCDs with photometry in the relevant J-PLUS filters described in Sect. \ref{Methodology} (see Table \ref{tab:filters}), which are reduced to 4\,649 objects after removing those with non-zero confusion and contamination flags in 2MASS. From this set, 1\,983 were recovered using our methodology and 2\,666 were not. We conducted an in-depth analysis of the 2\,666 UCDs following the two methodologies (astrometric and photometric) separately, to see in which steps of the process these objects are discarded.

In short, of this 2\,666 unrecovered objects, 1\,520 are lost because they do not meet our parallax, proper motion, and photometry constraints, while another 119 are discarded in the $\textit{G} - \textit{G}_{\rm RP}$ and $\textit{r} - \textit{z}$ cuts. The remaining 1\,027 are lost in the temperature/vgfb cutoff after the analysis with \texttt{VOSA}, some due to a bad SED fitting (vgfb > 12) and most of them due to an estimated temperature higher than 2\,900\,K. We have checked the latter and the vast mayority of them are M7\,V from Simbad that lie at the temperature limit, with estimated temperatures of 3\,000 - 3\,100\,K.


\subsection{New candidate UCDs vs. previously known} \label{new_vs_known}

In this section, we analyse the differences between previously known UCDs and the remaining candidate UCDs among our sample. For this, we cross-matched our candidate UCDs with the known UCDs sample described in Sect. \ref{known}. As indicated above, of the 9\,810 candidates identified by the proposed VO methodology, only 1\,983 were previously reported as UCD. This amounts to a total of 7\,827 new candidate UCDs in the sky coverage of J-PLUS DR2, which represents an increase of about 135\,\% (7\,827/5\,817) in the number of UCDs for this area.

Fig. \ref{fig:disthistboth} shows the distance distribution for our candidate UCDs, with good parallax conditions, discriminated by colour according to whether or not they were previously reported as UCD. It is clear that the new candidates detected are, on average, more distant, driven by the improvement of the quality of parallaxes with \textit{Gaia} EDR3. Of the 68 nearby objects found at distances smaller than 40\,pc, eight have not been previously reported as UCD. To check whether these objects could have been missed by other photometric surveys due to anomalies in their colours, we constructed a colour-colour diagram using \textit{$\textit{J}-\textit{K}_{\rm s}$} (2MASS) and $\textit{G}-\textit{G}_{\rm RP}$ (\textit{Gaia}) colours. Fig. \ref{fig:2massdiag} shows that this is not the case for any of these objects (black diamonds in the diagram).

A more in-depth view of this is the distance vs. effective temperature diagram shown in Fig. \ref{fig:distteff}. Here we can see how previously reported candidate UCDs tend to be at shorter distances for any value of the effective temperature. This trend is more clearly observed for higher temperature values, where the diagram shows how the new candidate UCDs cover the range of distances of the previously reported candidates and extend it to larger values, suggesting that our methodology allows us to go further in the search for new UCDs.

Going further, in Fig. \ref{fig:pmanalysis} we plot the absolute proper motions |$\mu_{\delta}$| and |$\mu_{\alpha}\cos{\delta}$| for our candidate UCDs with good proper motion conditions. It shows how the new candidate UCDs detected extend to smaller values of proper motion. Especially for values of proper motion of less than $15$\,mas\,yr$^{-1}$, the number of new candidates is significantly higher than the number of previously reported candidate UCDs, which reflects the improvement of the quality of proper motions with \textit{Gaia} EDR3.


%--------------------------------------------------------------------

\section{Machine learning analysis} \label{ml}

The filter system of J-PLUS offers a sufficiently high-dimensional space to reliably use ML techniques. We explored the ability to reproduce the presented search for candidate UCDs with a purely ML-based methodology that uses only J-PLUS photometry. Because the sample is strongly imbalanced, as a first step in the candidate UCDs identification, we proposed a filtering strategy to discard the objects that differ the most from the UCDs using the PCA algorithm. Then, with the reduced sample, SVM models were trained and fine-tuned to maximise the identification of candidate UCDs.

Principal component analysis~\citep{hotelling:33}, one of the most popular linear dimensionality reduction algorithms, is a non-parametric method that aims to reduce a complex data set to a lower dimension by identifying the axes that account for the largest amount of variance. The unit vectors defining each of these axes are called principal components. PCA works on the assumption that principal components with larger associated variance encompass the underlying structure of the data set in order to find the best basis for re-expressing it. The expectation behind this method, as with any method of dimensionality reduction, is that the entire data set can be well characterised along a small number of dimensions (principal components). By projecting the data set onto the hyperplane defined by these principal components, you ensure that the projection will preserve as much variance as possible.

The selection of PCA in our approach instead of other non-linear dimensionality reduction techniques, such as t-Distributed Stochastic Neighbor Embedding~\citep[t-SNE;][]{vandermaaten08} or Uniform Manifold Approximation and Projection~\citep[UMAP;][]{McInnes2018}, is mainly based on (1) the computational efficiency, since PCA allows projecting new data along the new axes without having to reapply the algorithm, and (2) the deterministic nature of the PCA solution, i.e., different runs of PCA on a given dataset will always produce the same results. These properties of PCA are crucial in our proposal, since we use the 2D representation of PCA to perform the filtering as a first step in our ML task.

Support vector machine is a supervised (requires labelled training data) ML algorithm that has been widely used in classification and regression problems~\citep{2013A&A...550A.120S,2017MNRAS.465.4556G}. The origin of this algorithm dates back to the late 70s, when \citet{vapnik} delved into the statistical learning theory. The idea behind SVM is to find a hyperplane that separates data into two classes while maximising a marging, defined as the distance from the hyperplane to the closest point across both classes. Thus, the SVM chooses the best separating hyperplane as the one that maximises the distance to these points, so the decision surface is fully specified by a subset of points on the inner edge of each class, known as support vectors. The SVM is a linear classifier, so if the data is not linearly separable in the instance space, we can gain linear separation by mapping the data to a higher dimensional space. To do so, different kernels are used, such as the polynomial or the radial basis function (RBF), since the kernel trick allows us to define a high-dimensional feature space without actually storing these features.


\subsection{PCA cut} \label{pca_cut}

In our methodology, we used J-PLUS DR2 data from one of the 20$\times$20\,deg$^2$ mentioned in Sect. \ref{Methodology}. We selected as features seven different J-PLUS colours built with the most relevant filters for UCDs, i.e., the reddest ones (see Table \ref{tab:filters}): $\textit{i}-\textit{z}$, $\textit{r}-\textit{i}$, $\textit{i}-\textit{J0861}$, $\textit{J0861}-\textit{z}$, $(\textit{i}-\textit{z})^2$, $(\textit{r}-\textit{i})^2$, and $\textit{r}-\textit{z}$. We discarded the filter \textit{J0660} because the available photometry in this filter is less abundant than in the others. Thus, we first built these variables from the J-PLUS photometry, discarding objects with no information in any of the required filters, and labelled the instances as positive or negative class using the candidate UCDs obtained with the previous methodology. After this, we ended up with a sample composed of 317 UCDs and 495\,274 non-UCD objects.

To perform the PCA, we first divided the sample into training (70\,\%) and test (30\,\%) sets using stratified sampling to ensure that these sets are representative of the overall population (have the same percentage of samples from each target class as the complete set). Thus, we trained the PCA model using the training set, obtaining that 93\,\% of the sample's variance lied along the two first principal components. Projecting the training data onto the hyperplane defined by these two principal components, the vast majority of non-UCD objects are clearly separated from the UCDs. Thus, it is possible to make a first cut in the identification of UCDs with this 2D projection, by defining a decision threshold (purple line in the Figure) and keeping only the objects that fall on the UCD side. Fig. \ref{fig:pca} shows the same projection for the entire sample (training + test). After this cut, we reduced our sample to 317 and 29\,732 UCD and non-UCD objects, respectively, achieving a 94\,\% reduction on the negative class. Despite still being strongly imbalanced, this reduced sample has a better balance between the negative and positive class, which facilitates better results when using the SVM.


\subsection{SVM model} \label{svm}

To develop the SVM model, we used the reduced sample obtained in the PCA filtering, keeping the same training and test set structure. We used the test set for the validation of the classification model. The seven J-PLUS colours described in Sect. \ref{pca_cut} were used as features in the training step.

Then, we conducted a search for the SVM's optimal hyperparameters on the training test. To do this, we created a grid for the SVM kernel and hyperparameters and did an exhaustive search over this parameter space using the \texttt{GridSearchCV} class from the \texttt{scikit-learn} package, which optimises the hyperparameters of an estimator by k-fold cross-validation using any score to evaluate the performance of the model. In our case, we used the recall score, which measures the ability of the classifier to find all the positive instances, since our priority is to identify as many candidate UCDs as possible. For the \texttt{GridSearchCV} class, we used ten k-folds and set the hyperparameter \texttt{class\_weight} to `balanced' to address the imbalance by adjusting the weights inversely proportional to the class frequencies. In the grid of hyperparameters, we tested the regularisation parameter $C$ for values of 1, 10, 100 and 1000, and the kernel scale $\gamma$ of the RBF kernel for 0.001, 0.01, 0.1, 1, 10 and 100.

After this search for the optimal hyperparameters, we obtained the best recall score with an RBF kernel and hyperparameters $C=10$ and $\gamma=0.001$, with a total recall, precision, and F1 score of 92\,\%, 15\,\%, and 26\,\%, respectively, on the test set.  Fig. \ref{fig:conf_mat_tr} shows confusion matrix on the test set. The confusion matrix is a performance measurement in machine learning classification that compares the labels predicted by the model (x-axis) with the ground-truth labels in the data set (y-axis). The most important thing to note here is that the SVM model manages to recover nearly all positive instances, which is our main priority, as we do not want to lose any candidate UCD in the process. Also, the SVM performs very well at identifying True Negatives (TN, negative instances predicted as negative). In conclusion, the model allows us to filter out the vast majority of non-UCD objects, while keeping almost all the candidate UCDs. However, the class imbalance of the data causes the number of False Positives (FP, negative instances predicted as positive) to be larger than the number of True Positives (TP, positive instances predicted as positive). This makes the analysis with VOSA still necessary to differentiate the final candidate UCDs.

\subsection{Blind test} \label{blind_test}

To validate the classifier's performance on unseen data, we applied our ML methodology on the J-PLUS DR2 data from another of the 20$\times$20\,deg$^2$ regions containing 607\,801 objects with good photometry in all relevant filters. Firstly, we used the same PCA model fitted with the previous region to perform the PCA filtering on this new region, reducing the total number of instances to 51\,343. We used the previously fitted SVM model to predict over this reduced set, obtaining a recall, precision, and F1 score of 91\,\%, 9\,\%, and 16\,\%, respectively. Fig. \ref{fig:conf_mat_new} shows the confusion matrix for this blind test. Thus, we ended up with 2\,606 (2\,379 + 227) objects to be analysed with VOSA for the final UCD identification, which means the SVM model achieved to discard $\sim$95\,\% (1 - 2\,379/51\,094) of the non-UCD objects that pass the PCA filtering.

We used the objects analysed with \texttt{VOSA} in the VO methodology for this same region to make a thorough analysis of our ML method. Thus, we found that, of these objects, the PCA filter removes those with $T_{\rm eff}\gtrsim4\,100$\,K, so this first cut is able to purge the initial set of the hottest objects. The ML methodology is more restrictive in terms of photometric quality, as it is only applicable to the objects with photometry in all the filters used to build the input features. This means that all the final candidate UCDs with no photometry in any of these filters (around 50\,\% for this region), obtained with the VO methodology, are not captured by the ML procedure. In summary, we concluded that the ML methodology is more efficient in the sense that it allows for a greater number of true negatives (non-UCD objects) to be discarded prior to analysis with \texttt{VOSA}, although it is a more restrictive method as it relies only on the photometry of the J-PLUS filters used. Another advantage of the proposed ML approach is that it consists of a single process instead of the three separate ones required in the VO methodology.

%--------------------------------------------------------------------

\section{Detection of strong emission line emitters} \label{flares}


Strong emission lines have been detected serendipitously in UCD optical spectra, both as transient flaring  phenomena  \citep{Liebert1999,Liebert2003,Martin2001,Schmidt2007} as well as steady  features  \citep{Schneider1991,Mould1994,Martin1999,Burgasser2011}. Stellar flares, events powered by the sudden release of magnetic energy, that is converted to kinetic energy of electrons and ions due to magnetic reconnection in the stellar atmosphere, are a common phenomenon around M dwarfs. Works such as those presented in \citet{flare_xray}, \citet{Berger2010} and \citet{arecibo} have confirmed that optical, radio and X-ray flares do occur in UCDs.

We decided to focus our search for strong emission on the H$\alpha$ and Ca~{\sc ii} H and K lines, important chromospheric activity indicators \citep{cincunegui}, which correspond to filters 11.0 ($J0660$) and 7.0 ($J0395$) in the J-PLUS filter system, respectively. Since this is a rare phenomenon, we decided to conduct this search on a larger sample of objects, including all the objects that met the $\textit{G} - \textit{G}_{\rm RP}$ and $\textit{r}-\textit{z}$ colour criteria presented in Sects. \ref{parallax}, \ref{pm} and \ref{colordiagram}. Therefore, since we did not apply the effective temperature cutoff, the search also covered spectral types hotter than those of the UCDs.

With this purpose, we developed a Python algorithm that detects any drop in magnitude in filters \textit{J0395} and \textit{J0660}. Firstly, the algorithm joins the J-PLUS DR2 photometry obtained in the search described in Sect. \ref{Methodology} to the shortlisted objects obtained with the methodology described in Sect. \ref{parallax}, \ref{pm} and \ref{colordiagram}. Then, object by object, it computes the magnitude ratio between the filter of interest and all its neighbours. We chose as neighbours the filters 6.0, 8.0 and 9.0 for the filter 7.0 (Ca~{\sc ii} H and K) and the filters 1.0 and 3.0 for the 11.0 (H$\alpha$). If this ratio is lower than a fixed threshold value (entered by the user) for any neighbouring filter, the algorithm recognises a  possible strong line emitter and plots the photometry of the object. For the object to be recognisable, we need at least photometry in one of the neighbouring filters, so we can detect this emission peak. The algorithm receives as input a file with the candidate UCDs photometry and returns both the plotted photometry of the objects with possible strong emission and a table with the computed magnitude drop for each of them. We were permissive with the fixed threshold, so as not to discard any interesting object, and imposed a value of 0.96. Then, we visually inspected all the possible strong emitters detected by the algorithm given this threshold.

Finally, we ended up with eight objects that exhibit significant emission peaks in the filters of interest, that are presented in Table \ref{tab:flares}. We used \texttt{VOSA} to estimate the effective temperature of these objects and found only one UCD, with $T_{\rm eff}=2\,500$\,K, among the eight objects (fifth object in Table \ref{tab:flares}). The remaining seven objects have estimated effective temperatures (see Table \ref{tab:flares}) typical of mid-M dwarfs \citep{zhang_2018_midm}. Fig. \ref{fig:flares} shows the photometry of the object with the highest line emission excess (first object in Table \ref{tab:flares}). Also, in Fig. \ref{fig:flares_imgs} we include images from the J-PLUS DR2 archive with the emission in different filters for the object with highest excess activity in the Ca~{\sc ii} H and K (first object in Table \ref{tab:flares}) and H$\alpha$ (seventh object in Table \ref{tab:flares}) emission lines. With this analysis, we underline the possibility of systematically detecting strong emission lines in UCDs and earlier M-type stars with photometric surveys such as J-PLUS.

For the fifth  object listed in Table \ref{tab:flares}, namely LP 310-34, we carried out a follow-up optical spectroscopy monitoring study. Five exposures of half an hour integration time each were obtained on January 12th, 2020 in service time (proposal 60-299, PI Martín) with ALFOSC attached to the Nordic Optical Telescope in La Palma. The grism number 4 and the slit with of 1.0 arcsec were selected providing a dispersion of 3.75 \AA pixel$^{-1}$ and a resolving power of R=700. Our spectra confirm that it is a very late M dwarf (dM8) with H$\alpha$ in emission \citep{Schmidt2007}. We measured an H$\alpha$ equivalent width of -14.6 \AA , using the gaussian profile integration option available in the IRAF task splot applied to the co-added spectrum of the five exposures. Individual measurements of the equivalent width in each spectrum ranged from -7.0 to -20.7 \AA , suggesting variability in the strength of the H$\alpha$ emission. This level of H$\alpha$ emission is not uncommon among late-M dwarfs \citep{Martin2010,Pineda2016}. No other emission lines were detected in our spectra.

One of the new strong line-emission candidates (sixth object in Table \ref{tab:flares}) was observed on April 21st, 2022 with the long-slit low-resolution mode of the SpeX instrument \citep{Rayner2003} at the NASA Infrared Telescope Facility (IRTF, program 2022A011, PI A. Burgasser). Preliminary analysis of the data indicates that the near-infrared spectrum is well matched by a M5 dwarf template (A. Burgasser, private communication). Further details of these observations and additional spectroscopic follow-up of the J-PLUS candidates presented in this work is planned for a future paper.

This study suggests that our J-PLUS search for strong emission lines may be revealing previously unknown sporadic very strong activity in otherwise normal late-M dwarfs. It is worth noting that our search for strong line emitters has detected as many objects with Ca~{\sc ii} H and K excess than with H$\alpha$ excess, and no object showing both excesses simultaneously. Events of strong Ca~{\sc ii} H and K line emission in normal late-M dwarfs may have important implications for studies of
exoplanetary space weather and habitability \citep{Yamashiki2019}.


%--------------------------------------------------------------------


\section{Conclusions} \label{conclusions}

Using a Virtual Observatory methodology, we provide a catalogue of 9\,810 candidate UCDs over the entire sky coverage of J-PLUS DR2. With 7\,827 previously not reported as UCD, we show there is still room for the discovery of these objects even with a small telescope such as the JAST80. Our main goal is to consolidate and further develop a search methodology, introduced in \citet{solano2019}, to be used for deeper and larger surveys such as J-PAS and Euclid, both being an ideal scenario for the study and discovery of UCDs thanks to their unprecedented photometric system of 54 narrow-band filters and excellent sensitivity, respectively. Further confirmation by spectroscopy of the UCD nature of these candidates goes beyond the scope of this study. However, the candidate UCDs that are reported in Simbad, but are not in our sample of known UCDs (see Sect. \ref{known}), mostly present spectral type M6\,V or are left out because they lack the luminosity class, so we expect the degree of contamination to be small.

The use of different approaches based on astrometry and photometry tends to minimise the drawbacks and biases associated to the search of ultracool objects: photometric-only selected samples may leave out peculiar UCDs not following the canonical trend in colour-colour diagrams and they can also be affected by extragalactic contamination. Proper motion searches may ignore objects with small values of projected velocity in the plane of the sky. Regarding parallax-based searches, they will be limited to the brightest objects with parallax values from \textit{Gaia}.

Based on our kinematics study, almost all our candidate UCDs can be considered thin disk members, with 268 of them being potential members of the thick disk. Also, five of the candidates are likely to belong to the Galactic halo. Using the \texttt{BANYAN}~$\Sigma$ tool, we find 48 candidate UCDs with a high Bayesian probability of belonging to seven different young moving associations, in 30 of the cases with a probability greater than 95\,\%. A further spectroscopic follow-up will be required to search for spectral signatures of youth. In the binarity analysis, we find 122 possible unresolved companions among our candidate UCDs. Searching for wide \textit{Gaia} companions of our candidate UCDs, we find 78 possible multiple systems (73 binary + 5 triple), six of them already tabulated by the WDS. We use \texttt{VOSA} to get an estimation of the effective temperature of the wide \textit{Gaia} companions identified in all the systems, finding that most of them are M-type stars.

Among the non-recovered known UCDs that lie in the sky coverage of J-PLUS DR2, we find that more than half are lost due to lack of photometric or astrometric information with enough quality. The remaining objects are discarded due to our conservative temperature cutoff at 2\,900\,K or a bad SED fitting (vgfb$>$12). Compared to previously reported candidates, the new ones are on average more distant and extend to smaller values of proper motion.

We achieve promising results when reproducing the search for UCDs with a purely ML-based methodology. In this approach, we find crucial the preliminar PCA filtering to deal with the strong imbalance of the data and discard the hottest objects. This allows us to significantly reduce the negative class and improve the classification capability of the posterior SVM model. Using the developed ML methodology to predict on unseen data, we are able to recover 91\,\% of the candidate UCDs found with the VO methodology, discarding a larger number of true negatives (non-UCD objects) before the analysis with VOSA in a faster way. This is a significant achievement, since the main bottleneck of the VO methodology is the high number of objects to be analysed with \texttt{VOSA}.

In this line, the real turning point would be to develop a ML methodology that more significantly filters the number of objects we need to analyse with \texttt{VOSA} for the final UCD identification. This is not a straightforward task due to the imbalance of the data and because the analysis with \texttt{VOSA} is based on complex theoretical models. To this end, we are exploring the use of independent component analysis in the initial filtering and ensemble learning in the classification step.

Finally, we develop an algorithm capable of detecting strong emission line emitters in the optical range. We identify four objects with strong excess in the filter corresponding to the Ca~{\sc ii} H and K emission lines and four other objects with excess emission in the H$\alpha$ filter.

\chapter{Detection of Flaring M dwarfs with multi-filter Photometry}
\label{chp:flares_paper}


% This chapter is based on the following paper:

% \noindent
% {\large{\textit{Ca~{\sc ii} and H$\alpha$ flaring M dwarfs detected with multi-filter photometry.}}}
% \textcolor{webbrown}{Mas-Buitrago et al. 2025, accepted for publication in Astronomy \& Astrophysics.}


%************************************************


Understanding and characterising the magnetic activity of M dwarfs is of paramount importance in the search for Earth-like exoplanets orbiting around them. Energetic stellar activity phenomena, such as flares or coronal mass ejections, which are common in these stars, are deeply connected with the habitability and atmospheric evolution of the surrounding exoplanets. We present a follow-up of a sample of M dwarfs with strong H$\alpha$ and Ca~{\sc ii} H and K emission lines identified with J-PLUS photometry in a previous work. We collected low-resolution NOT/ALFOSC and GTC/OSIRIS spectra, measuring the PC3 index for the spectral type determination. We used two-minutes cadence TESS calibrated light curves to identify and characterise multiple flares, and to calculate the rotation period of the two active M dwarfs found in our sample. We confirmed that the strong emission lines detected in the J-PLUS photometry are caused by transient flaring activity. We found clear evidence of flaring activity and periodic variability for LP 310-34 and LP 259-39, and estimated flare energies in the TESS bandpass between $7.4\times10^{30}$ and $2.2\times10^{33}$\,erg for them. We characterised LP 310-34 and LP 259-39 as very rapidly rotating M dwarfs with Ca~{\sc ii} H and K and H$\alpha$ in emission, and computed a rotation period of 1.69\,d for LP 259-39 for the first time. This work advocates the approach of exploiting multi-filter photometric surveys to systematically identify flaring M dwarfs, especially to detect episodes of strong Ca~{\sc ii} H and K line emission that may have important implications for exoplanetary space weather and habitability studies. Our results reveal that, apart from the already known H$\alpha$ flares, flare events in Ca~{\sc ii} H and K can also be detected using optical narrow-band filters in common M dwarfs.


%-------------------------------------------------------------------


% \section{Introduction}


% With lifespans of tens of billions of years \citep{adams1997}, M dwarfs are highly prevalent in the stellar population of the Galaxy, making up approximately 70\% of it \citep{henry1994,reid1995,reyle2021}. Thanks to their small size and low luminosity, the habitable zone in these cool stars is much closer than in their solar-like counterparts, which facilitates the detection of potentially habitable Earth-like exoplanets orbiting them, making M dwarfs major targets in the search for exoplanets. On the other hand, the nearby habitable zone around M dwarfs makes exoplanets more exposed to energetic events linked to stellar activity \citep{tilley2019,gunther2020,chen2021}, such as flares or coronal mass ejections (CMEs). Stellar flares are sudden releases of magnetic energy caused by magnetic reconnection events in the stellar atmosphere, accompanied by bursts of  isotropic electromagnetic radiation \citep{benz2010}, and are frequent phenomena in low-mass stars. Flares can release energies up to $\sim10^{37}$\,erg \citep{davenport2016}, in time spans ranging from minutes to several hours, and their spectrum is often modelled as a blackbody with a temperature between $9\,000-10\,000$\,K \citep{davenport2020,gunther2020}.

% It has been observed that a large fraction of M dwarfs are magnetically active, with a chromospheric activity often diagnosed by H$\alpha$ or Ca~{\sc ii} H and K line emission \citep{cincunegui2007,ibanezbustos2023}. The relation between the chromospheric emission in these lines is not straightforward, but exhibits a complex behaviour when studied over a large sample of M dwarfs, as the activity level in these two regions is not always correlated \citep{meunier2024}. Moreover, flare emission in the optical domain is also known to occur in these lines \citep{heinzel1994,kowalski2013}. In optical spectra of low-mass stars, strong emission lines have been detected serendipitously, both as transient flare events \citep{Martin2001,Liebert2003,Schmidt2007} and as steady features \citep{Mould1994,Martin1999,Burgasser2011}.

% Recent multi-filter photometric surveys, such as the Javalambre Photometric Local Universe Survey \citep[J-PLUS;][]{Cenarro2019} or the upcoming Javalambre Physics of the Accelerated Universe Astrophysical Survey \citep[J-PAS;][]{J-PAS}, with unique systems of 12 and 56 optical filters, respectively, may enable new ways to systematically detect strong emission lines in low-mass stars \citep{masbuitrago2022}. The spectral energy distributions provided by these surveys are suitable for identifying excess emission in narrow-band filters located at specific spectral features, such as the H$\alpha$ or Ca~{\sc ii} H and K lines, which could be caused by stellar flaring activity. Although the short exposure time characteristic of multi-filter photometric surveys hinders the detection of flare events, the large number of stars that can be analysed simultaneously in this way makes it feasible.

% High-precision, high-cadence photometric light curves (LCs) provided by surveys such as \textit{Kepler} \citep{kepler}, the \textit{Kepler} extended mission \citep[K2;][]{k2}, and the Transiting Exoplanet Survey Satellite \citep[TESS;][]{tess} are a powerful asset for understanding and studying the stellar activity of low-mass stars and brown dwarfs \citep[e.g.][]{martink1,doyle2019,doyle2022,kumbhakar2023}. TESS is a NASA mission launched in April 2018 with the primary objective of searching for transiting exoplanets around bright, nearby stars. Operating at optical wavelengths, the high-cadence photometric data provided by TESS capture insightful information about the magnetic activity of target stars, mainly in the form of periodic variability due to co-rotating star-spots or as sudden brightness outbursts caused by stellar flares.

% In this work, we present a spectroscopic follow-up of the sample of M dwarfs with strong H$\alpha$ and Ca~{\sc ii} H and K emission identified by \citet{masbuitrago2022} using J-PLUS photometry. Using TESS LCs, we perform a comprehensive study of the stellar activity of two active M dwarfs found in our sample, including a detailed analysis of their flaring activity and rotation period, as well as an estimation of their age. Moreover, we discuss the possible implications of the observed stellar activity on the evolution and habitability of exoplanets orbiting low-mass stars. In Section \ref{sec:obs}, we describe the spectroscopic observations collected for our sample. The reduced spectra of our targets and the analysis performed using TESS LCs are discussed in Section \ref{sec:results}. Section \ref{sec:habitability} presents a discussion of the impact of the magnetic activity of M dwarfs on planetary habitability. Finally, the main conclusions of this work are summarised in Section \ref{sec:conclusions}.


%-----------------------------------------------------------------


\section{Observations}\label{sec:obs}

\subsection{Sample selection}\label{sec:sample}

The sample studied in this work is the result of the search for strong emission lines performed in our previous work \citep{masbuitrago2022}, using multi-filter optical photometry from the Javalambre Photometric Local Universe Survey \citep[J-PLUS;][]{Cenarro2019}. For this, we developed a Python algorithm capable of detecting excess in the J-PLUS filters corresponding to the H$\alpha$ ($J0660$) and Ca~{\sc ii} H and K ($J0395$) emission lines. Following this approach, we identified eight M dwarfs with emission excess in these filters (four of them in each of the filters and none showing both excesses simultaneously). In the end, one of these objects was discarded for spectroscopic follow-up because it was not bright enough, resulting in a final sample of seven M dwarfs. Table~\ref{tab:targets} lists the selected targets.

The J-PLUS spectral energy distribution (SED) of each target star is provided in Appendix \ref{app:app_flares}. The excess emission in the $J0395$ filter is evident for J-PLUS0114, J-PLUS0744, J-PLUS0807, and J-PLUS0903. On the other hand, the SEDs of J-PLUS0226, J-PLUS0708, and J-PLUS0914 show strong emission in the $J0660$ filter. We attribute this behaviour to the fact that the star experiences flaring activity during the corresponding J-PLUS observing block, in which all filters are observed sequentially. The strategy for each J-PLUS observing block is to obtain, for the same pointing, three consecutive exposures per filter, with a total exposure time of approximately one hour \citep{Cenarro2019}. Flaring phenomena during the exposures for the filters of interest would explain the SED behaviour found. Given the low probability of observing a flare during the exposures for the filters of interest, it is easier to detect the less energetic and shorter-lived flares, which are more frequent and last a few minutes as we confirm in Section \ref{sec:flares}.

The estimated effective temperatures for these objects, obtained with the tool \texttt{VOSA}\footnote{\url{http://svo2.cab.inta-csic.es/theory/vosa/}} \citep{vosa}, locate them as mid-M dwarfs except for one, namely LP 310-34, with a $T_{\rm eff}=2\,500$\,K. As mentioned in \citet{masbuitrago2022}, we already carried out an spectroscopic follow-up for the latter that confirmed it as a late M dwarf (dM8) with H$\alpha$ in emission \citep{Schmidt2007}.


\subsection{Observational details}
We collected low-resolution optical spectra of our seven targets with The Alhambra Faint Object Spectrograph and Camera (ALFOSC) mounting on the 2.56-m Nordic Optical Telescope (NOT) with proposal number 66-208 (P.I. ELM). Also, we observed two bright targets (J-PLUS DR2 J0807+32 and J-PLUS DR2 J0903+34 in Table \ref{tab:targets}) with the Optical System for Imaging and low-Intermediate-Resolution Integrated Spectroscopy (OSIRIS) mounting on the 10.4-m Gran Telescopio Canarias (GTC), at the Roque de los Muchachos Observatory on the island of La Palma, Spain, with programme GTCMULTIPLE2I-22B (P. I. ELM).

ALFOSC is equipped with a Teledyne e2v CCD231-42-g-F61 back illuminated, deep depletion, astro multi-2 detector. The detector dimension is 2\,048$\times$2\,064 pixels with a scale of 0.2138 arcsec/pix. The NOT/ALFOSC observation was executed under visitor mode during the nights of January 26-27, 2023 (observers PMB \& JYZ). We used a 1.0-arcsec slit, and \#4 grism, which provide a wavelength range from 3\,200 \AA\ to 9\,600 \AA\ with a resolution power $R\approx360$.

OSIRIS is a commonly used instrument of GTC. It covers the wavelength range $3\,650- 10\,050$\,\AA\ and has an effective field of view of 7.5$\times$6.0 arcmin. OSIRIS has two Marconi CCD44-82 (2\,048$\times$4\,096 pixels) detectors with gap in between. The 2$\times$2 binned pixel size is 0.254 arcsec/pix. In the mode of long-slit spectroscopy, the object is centred on the slit at the coordinate $\rm{X}
=250$ of the CCD2. The GTC/OSIRIS observation was executed under service mode. We requested as conditions a maximum seeing of 1.2\,arcsec, cloud free sky, and grey moon phase, using the R1000B grism and a 1.2-arcsec slit under the parallactic angle. This configuration yields a wavelength coverage from 3\,600\,\AA\ to 7\,900\,\AA\ with a resolution power $R\approx500$. Table~\ref{tab:obs} shows the record of observations.


%--------------------------------------------------------------------


\subsection{Data reduction}
We reduced both the GTC/OSIRIS and NOT/ALFOSC data using v1.12 of \texttt{PypeIt} \citep{pypeit:zenodo,pypeit:joss_pub}, a community-developed open-source Python package for semi-automated reduction of spectroscopical data in astronomy. \texttt{PypeIt} supports a long list of spectrographs and provides the code infrastructure to automatically process the image, identify the slit in a given detector, extract the object spectra, and perform wavelength calibration. We observed the standard stars HD~19445 and Feige~110 for flux calibration of NOT/ALFOSC and GTC/OSIRIS data, respectively.


%--------------------------------------------------------------------


\section{Results and discussion}
\label{sec:results}

\subsection{Reduced spectra}
\label{sec:reduced_sp}


Figure \ref{fig:spectra_all} shows the co-added spectra for the observed targets. We note that no intense steady line emission is observed in the spectra (for examples of strong line emission in low-resolution spectra, see Fig. 1 in \citealp{Burgasser2011} or Figs. 10 and 11 in \citealp{Schmidt2007}), confirming that the excess emission detected in the J-PLUS photometry is not steady and is indeed caused by transient flaring activity. Moreover, objects with excess emission in the J-PLUS Ca~{\sc ii} H and K filter show no apparent differences in their spectral features compared to objects with excess emission in the J-PLUS H$\alpha$ filter (see Table \ref{tab:targets}), suggesting that the flaring activity detected in Ca~{\sc ii} H and K is not particular to a specific type of star. Hence, it follows that common M dwarfs experience two types of flares, those already well-known in H$\alpha$ and those in Ca~{\sc ii} H and K revealed in this work.

Several spectroscopic indices have been explored for the spectral classification of M dwarfs \citep{lepine2003} and, in particular, for late-M dwarfs using low-resolution optical spectra \citep{kirkpatrick1995, martin1996, martin1999b}. To derive spectral types for our sample, we measured the PC3 index \citep{martin1999b}, which is a reliable indicator of spectral type in the [M2.5, L1] range and has been used consistently in the literature \citep{crifo2005,martin2006,Martin2010,phanbao2006,reyle2006,phanbao2008}. The PC3 index is a pseudo-continuum spectral ratio between the $8230-8270$\,\AA\,(numerator) and $7540-7580$\,\AA\,(denominator) intervals, which can be used to derive spectral types between M2.5 and L1 following the calibration presented by \citet{martin1999b}:

\begin{equation}
    \rm{SpT}=-6.685+11.715\times (\rm PC3)-2.024\times (\rm PC3)^2.
    \label{eq:ffd}
\end{equation}

Table \ref{tab:pc3} lists the PC3 index and the adopted spectral type, with an uncertainty of $\pm0.5$ subclasses, for our targets. The classification obtained for J-PLUS0807 is consistent with that provided in \citet{Schmidt2007}, who derived a spectral type of dM8, with an uncertainty of $\pm0.5$ subclasses, by visual comparison of the spectra to spectral standards. These results confirm the rest of our sample, still spectroscopically unclassified in the literature, as mid-M dwarfs.


The obtained spectra confirm both J-PLUS0807 and J-PLUS0903 as active M dwarfs with Ca~{\sc ii} H and K and H$\alpha$ in emission, while the rest of the targets show no signs of activity. Figure \ref{fig:spectra_red} shows a close-up view of the spectral region of interest for these stars, with prominent Ca~{\sc ii} H and K, H$\delta$, H$\gamma$, H$\beta$ and H$\alpha$ emission lines. We quantified the H$\alpha$ emission using the \texttt{specutils}\footnote{\url{https://specutils.readthedocs.io/en/stable/index.html}} \citep{specutils} Python package, obtaining an H$\alpha$ equivalent width of $-16.80\,\AA$ and $-5.90\,\AA$ for the co-added NOT/ALFOSC spectra, and of $-18.36\,\AA$ and $-6.08\,\AA$ for the co-added GTC/OSIRIS spectra of J-PLUS0807 and J-PLUS0903, respectively. These results correspond to levels of H$\alpha$ emission that are not uncommon among this type of stars \citep{Schmidt2007,Martin2010}. We found no significant differences between the equivalent width measurements for the individual spectra of each exposure.


%--------------------------------------------------------------------



\subsection{Light curve analysis}
\label{sec:tess}

We queried the Mikulski Archive for Space Telescopes (MAST\footnote{\url{https://mast.stsci.edu/portal/Mashup/Clients/Mast/Portal.html}}) to fetch high-cadence photometric data for our sample. We found two-minutes cadence TESS calibrated LCs for the two closest stars, J-PLUS0807 and J-PLUS0903, with TIC IDs 461654150 and 166597074, respectively. Table \ref{tab:TESS_data} shows the details of the retrieved LCs, which are processed using the pipeline developed by the Science Processing Operations Centre \cite[SPOC;][]{spoc}. The contamination ratio, \texttt{Rcont}, listed in the TESS Input Catalog \citep{tic8_2} is 10\% and 0.22\% for J-PLUS0807 and J-PLUS0903, respectively. To further study a possible contamination of the TESS photometry for these two stars, we used the \texttt{tpfplotter}\footnote{\url{https://github.com/jlillo/tpfplotter}} \citep{tpfplotter} tool to explore the target pixel files (TPFs) of the fields of our targets. Thus, we only found a $\sim1\%$ contamination, obtained from the difference in \textit{Gaia} magnitudes, from \textit{Gaia} sources within the photometric apertures selected by the SPOC pipeline to process the LCs of the two stars.


We identified clear evidence of flaring activity and periodic variability in the retrieved two-minutes cadence LCs for J-PLUS0807 and J-PLUS0903, which are analysed in detail in Sections \ref{sec:flares} and \ref{sec:periods}. For the remaining five stars in our sample, that do not have processed, short-cadence TESS data, we used the Python package \texttt{lightkurve} \citep{lightkurve} to manually extract LCs from the TESS Full Frame Images cutouts, but did not find any flare events or periodic variability signals. We also searched for time-resolved UV data from the NASA Galaxy Evolution Explorer \citep[GALEX;][]{galex} mission for our targets, using the \texttt{gPhoton} \citep{gphoton} database and software, but we did not find any.


%--------------------------------------------------------------------


\subsubsection{Flares}
\label{sec:flares}


For our analysis, we used the Pre-search Data Conditioning Simple Aperture Photometry \citep[PDCSAP;][]{smith2012,stumpe2012,stumpe2014} flux, available in the TESS LCs retrieved for J-PLUS0807 and J-PLUS0903, which is already corrected from long-term trends, instrumental effects, and excess flux due to starfield crowding. We removed all data points with non-zero quality flags, after visually verifying that points with 512 (`Impulsive outlier removed before cotrending') or 1024 (`Cosmic ray detected on collateral pixel row or column') quality flags were not actually part of a real flare. We identified several flare events in all the J-PLUS0807 and J-PLUS0903 TESS LCs. For example, Figure \ref{fig:flares_lc} shows the LC of J-PLUS0903 (top left panel) and one of the LCs of J-PLUS807 (sector 44, bottom left panel), with multiple flaring episodes observed in both of them. Moreover, the right panel provides a zoomed-in view of the flare event occurring around day 1890 (BJD - 2457000 days) in the J-PLUS0903 LC.


We used the open-source Python software  \texttt{AltaiPony}\footnote{\url{https://altaipony.readthedocs.io/en/latest/}} \citep{davenport2016,ilin2021} to automatically identify and characterise flares in the LCs. Prior to flare detection, we detrended the LCs using a Savitzky-Golay filter \citep{Savitzky1964} to remove rotational modulation trends. For flare detection, we followed the same procedure as \citet{davenport2014,doyle2019,doyle2022,kumbhakar2023}, identifying flares as two or more consecutive points that are $2.5\sigma$ above the local scatter of the data \citep{chang2015}. As reported by \citet{vida2017,doyle2018}, we found no obvious relationship between flaring activity and rotational phase. \texttt{AltaiPony} automatically determines several flare properties, such as start and end times, flare amplitude, and equivalent duration (ED), which is the area under the flare light curve in units of seconds. Using the observed NOT/ALFOSC spectra and the tool \texttt{Specphot}\footnote{\url{http://svo2.cab.inta-csic.es/theory/specphot/}} \citep{specphot}, developed and maintained by the Spanish Virtual Observatory\footnote{\url{http://svo2.cab.inta-csic.es}}, we obtained the star quiescent flux in the TESS bandpass. We relied on the calculated flux and \textit{Gaia} distances of our targets to derive the quiescent stellar luminosity and multiplied it by the ED to obtain the flare energy in the TESS bandpass. We obtained $L_{\rm TESS}=2.3\times10^{29}$~erg\,s$^{-1}$ and $L_{\rm TESS}=2.2\times10^{30}$~erg\,s$^{-1}$ for the quiescent luminosity in the TESS bandpass of J-PLUS0807 and J-PLUS0903, respectively. Table \ref{tab:flares} details the flare properties for each target.

The flare energy and rate obtained for our targets are typical of active, fast rotating mid- and late-M dwarfs \citep{doyle2019,ramsay2020,stelzer2022}. With the observed flares for J-PLUS0807, we built the cumulative flare frequency distribution (FFD) to study the flare rate as a function of flare energy. This was not possible for J-PLUS0903 due to the low number of events available. FFDs can be expressed as a power-law relation \citep{stelzer2007,lin2019}:

\begin{equation}
    \frac{d \nu}{d E_{\rm F}}\sim E_{\rm F}^{-\alpha},
    \label{eq:ffd}
\end{equation}

where $\nu$ is the cumulative flare rate for a given flare energy $E_{\rm F}$, and $1-\alpha$ is the slope of a linear fit to a log-log representation. To fit the FFD, we relied on \texttt{AltaiPony}'s \texttt{FFD.fit\_powerlaw()} method, which fits the power-law parameters simultaneously using the Markov Chain Monte Carlo method described in \citet{wheatland2004}. Since the detection probability decreases in the low-energy regime, where flares may go undetected due to the noise present in the LC, we discarded the low-energy tail of the FFD in the fit of the power-law \citep{hawley2014,chang2015,ilin2021}. Figure \ref{fig:ffd} shows how the power-law relation breaks down around $E_{\rm F}=10^{31.5}$~erg, which is the threshold we applied to consider flares in the FFD fitting. Following this methodology, we obtained $\alpha=1.74_{-0.17}^{+0.20}$ for J-PLUS0807, which is in agreement with what \citet{lin2019}, \citet{raetz2020}, and \citet{murray2022} found for their samples of 548, 56 and 85 flaring M dwarfs, respectively. We found that the less energetic flares, which are more frequent as illustrated in the FFD, are also shorter in duration and the easiest to detect with the J-PLUS observation strategy (see Section \ref{sec:sample}).


%--------------------------------------------------------------------



\subsubsection{Rotation periods}
\label{sec:periods}

All TESS LCs retrieved for J-PLUS0807 and J-PLUS0903 show a clear periodic variability, which usually arises due to co-rotating star-spots that appear and disappear from the line of sight. Therefore, we relied on a Lomb-Scargle periodogram \citep{lomb,scargle}, using the \texttt{astropy} Python package \citep{astropy}, to search for the rotation period of each of our targets. Figure \ref{fig:periods} shows the periodogram for each of the  targets and the phase-folded LCs with the chosen periods, which are very prominent in the periodograms.

For J-PLUS0807, we computed the period using the data from all available sectors and obtained $P_{\rm rot}=0.3450$\,d, which is consistent with the values reported by \citet{guangwei2024} using TESS data from sectors 20, 45, 46 and 47, \citet{seli2021} using only TESS data from sector 20, and \citet{newton2016}, who relied on photometry from the MEarth Project \citep{berta2012}. For J-PLUS0903, we obtained $P_{\rm rot}=1.69$\,d, which is the first estimation for the rotation period of this object. As a measure of the uncertainty of the peak position in the periodogram, we used the standard deviation of all the values with a power greater than the half height of the periodogram peak, obtaining 0.0002\,d and 0.02\,d for J-PLUS0807 and J-PLUS0903, respectively.

We confirmed that our targets were the sources of the detected variability using the \texttt{TESS\_localize}\footnote{\url{https://github.com/Higgins00/TESS-Localize}} \citep{tess_localize} Python package.

The computed rotation periods place our two targets as very fast rotators \citep{irwin2011}, which is deeply interlinked with the activity level observed. After reaching the main sequence, low-mass stars slowly spin-down due to the loss of angular momentum by stellar winds, thus undergoing a decrease in their magnetic activity over time \citep{yang2017,davenport2019,raetz2020} that may also be dependent on stellar metallicity \citep{see24}, which makes obtaining robust age estimations for low-mass stars notoriously difficult. To explore this, we relied on \texttt{stardate}\footnote{\url{https://stardate.readthedocs.io/en/latest/}} \citep{stardate}, a Python tool that combines isochrone fitting with gyrochronology for measuring stellar ages. In our case, we included magnitudes from the Two-Micron All Sky Survey \citep[2MASS;][]{2mass}, parallax and magnitudes from \textit{Gaia} DR3, magnitudes from the Sloan Digital Sky Survey \citep[SDSS;][]{sdss}, and the rotation periods obtained in this work as input parameters. Following this procedure, we obtained an age of $0.79^{+0.62}_{-0.09}$\,Gyr and $1.94^{+1.74}_{-1.26}$\,Gyr for J-PLUS0807 and J-PLUS0903, respectively, which is in agreement with the values found in the literature for fast rotators \citep{newton2016,doyle2019}. Here, the chosen value and uncertainties correspond to the median and $\pm1\sigma$ thresholds of the Markov Chain Monte Carlo samples computed by \texttt{stardate}.


%--------------------------------------------------------------------


\section{Planetary habitability}
\label{sec:habitability}

Understanding the impact of the magnetic activity of M dwarfs on a planet's evolution and habitability is of crucial interest in the search for Earth-like planets. The common flaring activity and CMEs, together with the nearby habitable zone of these stars, can lead to substantial alteration of planetary atmospheres or even their erosion. It is unclear whether stellar flares are beneficial or detrimental to the habitability of exoplanets. It is possible that UV radiation emitted during flare events can trigger the development of prebiotic chemistry \citep{rimmer2018,airapetian2020}. Although abiogenesis would potentially be slower compared to prebiotic Earth due to the lower emission of M dwarfs at these wavelengths \citep{rugheimer2015,ranjan2017}, flares could provide the lacking UV energy \citep{buccino2007,jackman2023}. In this line, the flare events in Ca~{\sc ii} H and K emission lines revealed in this work may play an important role.

Continued exposure to $E_{\rm bol}>10^{34}$\,erg flares would make the presence of ozone layers impossible on any habitable zone terrestrial exoplanet orbiting an M dwarf \citep{tilley2019,chen2021}. Moreover, \citet{berger2024} recently demonstrated that the 9\,000\,K blackbody commonly assumed for flares underestimated the FUV emission for 98\% of their sample, which would significantly increase the number of stars with sufficient flaring activity to fall into the ozone depletion zone from previous studies. Following the relation provided by \citet{seli2021}, we converted the TESS energies of the detected flares to bolometric flare energies. Thus, we obtained a rate of 0.02\,day$^{-1}$ for $E_{\rm bol}>10^{34}$\,erg flares for J-PLUS0807, which is an order of magnitude lower than the rate found by \citet{tilley2019} for the ozone layer to be eroded in habitable zone terrestrial exoplanets around M dwarfs. For J-PLUS0903, none of the flares exceeded this energy threshold.


%--------------------------------------------------------------------


\section{Conclusions} \label{sec:conclusions}

This work serves as a follow-up study of the sample of M dwarfs with strong excess emission in the J-PLUS filters corresponding to Ca~{\sc ii} H and K and H$\alpha$ emission lines, identified in our previous work \citep{masbuitrago2022}. Using low-resolution spectra collected with NOT/ALFOSC and GTC/OSIRIS, we measured the PC3 spectral index of our targets and spectroscopically confirmed the mid-M dwarf nature of six of them for the first time. We confirmed that the strong excess emission detected in the J-PLUS photometry is caused by transient flare events, suggesting that two types of flares are detected using narrow-band optical photometry in common M dwarfs, those already well-known in H$\alpha$ and those in Ca~{\sc ii} H and K presented in this work. Work dedicated to the study of flares in large M dwarf samples usually focuses only on H$\alpha$ flare events, which could lead to an underestimation of the number of flaring M dwarfs. In the future, multi-wavelength simultaneous observations will be essential to further study the flaring activity of M dwarfs.

We analysed two-minutes cadence TESS LCs for J-PLUS0807 and J-PLUS0903 and performed a thorough characterisation of the multiple flare events observed in them. We estimated the flare energies in the TESS bandpass and found them to be in the range of $7.4\times10^{30}-2.2\times10^{33}$\,erg. We found clear signs of a periodic variability in the TESS LCs, confirming the previously reported ultra-fast rotating nature of J-PLUS0807 with data from sectors 20, 44, 45, 46, and 47. Also, we computed for the first time a rotation period of 1.69\,d for J-PLUS0903.

This work demonstrates the potential of multi-filter photometric surveys such as J-PLUS or the upcoming J-PAS to systematically detect flare events in M dwarfs, especially episodes of strong Ca~{\sc ii} H and K line emission that may have important implications for exoplanetary space weather and habitability studies. Using a detection algorithm such as the one developed in \citet{masbuitrago2022}, it is possible to identify a sample of candidates that can be confirmed and analysed with spectroscopic follow-up and high-cadence photometric LCs from TESS or similar missions such as K2. It also highlights the fundamental role of stellar flares in shaping the habitability of exoplanets. A high frequency of energetic flares implies that planets around these stars may experience significant atmospheric erosion and elevated levels of surface radiation, although it could also trigger the development of prebiotic chemistry.

%--------------------------------------------------------------------

%************************************************
\chapter{Autoencoders and Deep Transfer Learning in CARMENES}
\label{chp:autoencoders_paper}


% This chapter is based on the following paper:

% \noindent
% {\large{\textit{Using autoencoders and deep transfer learning to determine the stellar parameters of 286 CARMENES M dwarfs.}}}
% \href{https://ui.adsabs.harvard.edu/link_gateway/2024A&A...687A.205M/doi:10.1051/0004-6361/202449865}{Mas-Buitrago et al. 2024, A\&A, 687, A205.}

%************************************************


Deep learning (DL) techniques are a promising approach among the set of methods used in the ever-challenging determination of stellar parameters in M dwarfs. In this context, transfer learning could play an important role in mitigating uncertainties in the results due to the synthetic gap (i.e. difference in feature distributions between observed and synthetic data). We propose a feature-based deep transfer learning (DTL) approach based on autoencoders to determine stellar parameters from high-resolution spectra. Using this methodology, we provide new estimations for the effective temperature, surface gravity, metallicity, and projected rotational velocity for 286 M dwarfs observed by the CARMENES survey. Using autoencoder architectures, we projected synthetic PHOENIX-ACES spectra and observed CARMENES spectra onto a new feature space of lower dimensionality in which the differences between the two domains are reduced. We used this low-dimensional new feature space as input for a convolutional neural network to obtain the stellar parameter determinations. We performed an extensive analysis of our estimated stellar parameters, ranging from 3050 to 4300\,K, 4.7 to 5.1\,dex, and $-$0.53 to 0.25\,dex for $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H], respectively. Our results are broadly consistent with those of recent studies using CARMENES data, with a systematic deviation in our $\textit{T}_{\rm eff}$ scale towards hotter values for estimations above 3\,750\,K. Furthermore, our methodology mitigates the deviations in metallicity found in previous DL techniques due to the synthetic gap. We consolidated a DTL-based methodology to determine stellar parameters in M dwarfs from synthetic spectra, with no need for high-quality measurements involved in the knowledge transfer. These results suggest the great potential of DTL to mitigate the differences in feature distributions between the observations and the PHOENIX-ACES spectra.


%-------------------------------------------------------------------


\section{Context}

% Low-mass dwarfs are the most common type of stars in the Galaxy, constituting approximately 70\% of the stellar population  \citep{henry1994,reid1995,reyle2021}. In particular, M dwarfs, which are smaller, cooler, and fainter than Sun-like stars are of great importance in the study of exoplanets because of their prevalence, longevity, and proximity. Their small size and lower luminosity make it easier to detect Earth-sized planets in their habitable zones.
% As a result, several programs have been established with the goal of identifying potentially habitable planets orbiting M dwarfs. Notable examples include ground-based instruments like the Echelle Spectrograph for Rocky Exoplanet and Stable Spectroscopic Observations \citep[ESPRESSO,][]{pepe21} and its predecessor, the High-Accuracy Radial velocity Planet Searcher \citep[HARPS,][]{mayor2003,bonfils13}, or the Calar Alto high-Resolution search for M dwarfs with Exoearths with Near-infrared and optical Echelle Spectrographs \citep[CARMENES,][]{Quirrenbach16,Quirrenbach20}.

The precise determination of the stellar parameters of M dwarfs is crucial to improve our understanding of planetary formation and evolution, which depends fundamentally on the thorough characterisation of their host stars \citep{cifuentes2020}. However, well-established photometric and spectroscopic methods for determining these parameters encounter particular challenges, mainly due to the inherent faintness of M dwarfs and their frequent manifestation of strong stellar activity. Specifically for spectroscopic analyses, establishing the spectral continuum can be a difficult task.
Despite these problems, numerous efforts have been devoted to estimating photospheric parameters in M dwarfs, including effective temperature ($\textit{T}_{\rm eff}$), surface gravity (log \textit{g}), and metallicity ([M/H]). Several methods have proven successful in inferring these parameters, such as fitting synthetic spectra, as in  \citet[][hereafter Pass19]{pass2019} and  \citet[][hereafter Mar21]{mar21}, pseudo-equivalent widths (pEWs) \citep[e.g.][]{Mann2013,Mann2014,Neves2014},
spectral indices \citep[e.g.][]{RojasAyala2010,Rojas2012}, empirical calibrations \citep[e.g.][]{casagrande08,Neves2012}, interferometry \citep[e.g.][]{Boyajian2012,Rabus2019}, and machine learning  \citep[e.g.][hereafter Pass20]{Antoniadis2020,pass20}.

The approaches based on pEWs, measurements of the strength of absorption lines in a spectrum, and spectral indices, calculated from carefully chosen spectral regions --and  often derived from absorption lines or bands--, leverage their sensitivity and correlation with stellar parameters (mainly, $\textit{T}_{\rm eff}$ and [Fe/H]). As a recent example of these approaches, \citet{Khata2020} determined $\textit{T}_{\rm eff}$ and  metallicities, among other parameters, for 53 M dwarfs using \textit{H}- and \textit{K}-band pEWs and H$_{2}$O indices.
Another approach relies on empirical calibrations based on observations of M dwarfs that have an F, G, or K binary companion with known metallicity. This is grounded in the idea that the metallicity of an M dwarf is comparable to that of the hotter primary star, assuming the system originated from the same proto-stellar cloud \citep{Neves2012,montes2018,duque24}. For example, \citet{Rodriguez2019} employed the relationships of \citet{Newton2015} and \citet{Mann2013b} to derive $\textit{T}_{\rm eff}$ and metallicity, respectively, from moderate-resolution spectra of 35 M dwarfs from the \textit{K2} mission.
Numerous spectral indices have also been empirically calibrated. For instance, \citet{Veyette2017} determined $\textit{T}_{\rm eff}$, [Fe/H], and [Ti/H] from high-resolution \textit{Y}-band spectra of 29 M dwarfs by combining spectral synthesis with empirically calibrated indices and pEWs using FGK+M systems \citep{bonfils2005,Mann2013}.

Interferometric measurements have also proven useful for deriving index-based calibrations for $\textit{T}_{\rm eff}$ \citep{Mann2013b}, performing empirical calibrations for $\textit{T}_{\rm eff}$ \citep{maldonado2015,Newton2015}, or determining $\textit{T}_{\rm eff}$ from interferometric observations in combination with parallaxes and bolometric fluxes \citep{Boyajian2012,vonBraun2014,Rabus2019}. However, their application is limited to a relatively small number of stars due to the requirement that they must be bright and nearby.

The fitting of synthetic spectra relies on a minimisation algorithm to find the synthetic spectrum that best matches the observed spectrum. Variations exist in terms of the synthetic grid employed (e.g. BT-Settl, PHOENIX-ACES, MARCS), using high or low spectral resolution, and the number and wavelength of features selected for comparison.
For example, the BT-Settl models \citep{allard2012,Allard2013} were used by \citet{GaidosMann2014} and \citet{mann2015} to derive $\textit{T}_{\rm eff}$ values for M dwarfs with low-resolution visible SNIFS (Supernova Integral Field Spectrograph) spectra, and by \citet{Rajpurohit2018} to compute $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] for 292 M dwarfs using high-resolution CARMENES spectra \citep{reiners2018}. \citet{Kuznetsov2019} applied BT-Settl models to intermediate-resolution spectra from the visible arm of VLT/X-shooter \citep[intermediate resolution, high-efficiency spectrograph,][]{Vernet2011} to determine $\textit{T}_{\rm eff}$, log \textit{g}, [Fe/H], and $\textit{v}\sin{i}$ for 153 M dwarfs. More recently, \citet{Hejazi2020} derived $\textit{T}_{\rm eff}$, $\log{g}$,
metallicity [M/H], and alpha-enhancement [$\alpha$/Fe] of 1\,544 M dwarfs and subdwarfs from low- to medium-resolution spectra collected at the Michigan-Dartmouth-MIT observatory, Lick Observatory, Kitt Peak National Observatory, and Cerro Tololo Interamerican Observatory. Additionally, \citetalias{mar21} determined $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] for a sample of 343 M dwarfs observed with CARMENES using a Bayesian implementation of the spectral synthesis technique, the \texttt{SteParSyn}\footnote{\url{https://github.com/hmtabernero/SteParSyn}} code \citep{Tabernero2022}.

Based on the PHOENIX-ACES library \citep{Husser2013}, \citet{Birky2017} derived $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] for late-M and early-L dwarfs from high-resolution near-infrared APOGEE spectra \citep{Wilson2010}. Similarly, \citet{pass18} and  \citet[][hereafter Schw19]{schw19} determined these parameters for M dwarfs observed with CARMENES in the visible wavelength region. Building upon these works,  \citetalias{pass2019} extended the analysis by determining $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H]  not only from the visible range covered with CARMENES but also from the near-infrared and the combination of visible and near-infrared data. The comparison conducted in \citetalias{pass2019} led to the conclusion that utilising both spectral ranges for parameter determination maximises the amount of available spectral information while minimising possible effects caused by imperfect modelling.
The MARCS model atmospheres \citep{Gustafsson2008} have also been employed to compute photospheric parameters. For instance, in a recent study by \citet{Souto2020}, $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] were determined for 21 M dwarf mid-resolution APOGEE \textit{H}-band spectra using MARCS models and the {\ttfamily turbospectrum} code \citep{Plez2012} through the {\ttfamily bacchus} wrapper \citep{Masseron2016}.
Similarly, \citet{Sarmento2021} derived $\textit{T}_{\rm eff}$, log \textit{g}, [M/H], and microturbulent velocity $v_{\rm mic}$ for 313 M dwarfs from APOGEE \textit{H}-band spectra using MARCS models, {\ttfamily turbospectrum}, and {\ttfamily iSpec} python code \citep{BlancoCuaresma2014}.

As large surveys release extensive databases containing thousands of stars, there is a need for flexible and automated methods capable of handling vast amounts of data to infer stellar atmospheric parameters. In this sense, machine learning (ML) techniques have also been used for determining photospheric parameters for M dwarfs from stellar spectra. For example, \citet{Sarro2018} proposed an automated procedure based on genetic algorithms to identify pEWs and integrated flux ratios from BT-Settl models that yield good estimations of $\textit{T}_{\rm eff}$, log \textit{g}, and [M/H] for spectra from the NASA Infrared Telescope Facility (IRTF). Also based on pEWs, \citet{Antoniadis2020} present an ML tool, named {\ttfamily ODUSSEAS}, to derive $\textit{T}_{\rm eff}$ and [Fe/H] of M dwarf stars from 1D spectra for different resolutions. In \citet{Birky2020}, {\ttfamily The Cannon} \citep{Ness2015,Casey2016}, a data-driven spectral-modelling and parameter-inference framework, is used to estimate $\textit{T}_{\rm eff}$ and [Fe/H] for 5\,875 M dwarfs in the APOGEE \citep{Abolfathi2018} and {\it Gaia} DR2 \citep{GaiaDR2} surveys. Using the Stellar LAbel Machine \citep[SLAM,][]{Zhang2020}, \citet{Li2021} trained a model with APOGEE stellar labels and synthetic spectra from the BT-Settl model, resulting in the determination of $\textit{T}_{\rm eff}$ and [M/H] for M dwarfs from the LAMOST DR6\footnote{\url{http://dr6.lamost.org/}} catalogue.

This study extends previous works on applying deep learning (DL) to predict stellar parameters from high-resolution spectra observed with CARMENES. \citetalias{pass20} presented a DL approach where convolutional neural networks (CNNs) were trained on synthetic PHOENIX-ACES models to estimate $\textit{T}_{\rm eff}$, log \textit{g}, [M/H], and $\textit{v}\sin{i}$ for 50 M dwarfs observed with CARMENES. After a thorough analysis of their methodology, in which different architectures and spectral windows were tested, they found that all DL models were able to estimate stellar parameters from synthetic spectra in a precise and accurate way. However, when testing these models on the CARMENES spectra, they found significant deviations for the metallicity because of the synthetic gap \citep{fabbro2018,Tabernero2022}, which is the difference in feature distributions between synthetic and observed data.
In a more recent study, \citet[][hereafter Bello23]{bello2023} employed a deep transfer learning (DTL) approach to mitigate the uncertainties associated with the synthetic gap (see their Figs. 1 and 2). Following the training of DL models on a large set of synthetic spectra from the PHOENIX-ACES model, the models underwent fine-tuning based on external knowledge about stellar parameters. This external knowledge included 14 stars from the CARMENES survey with interferometric angular diameters measured by \citet{Boyajian2012}, \citet{vonBraun2014}, and references therein. Additionally, it was supplemented with five mid-to-late M dwarf stars from \citet{passegger2022}. They achieved the determination of new $\textit{T}_{\rm eff}$ and [M/H] values for 286 M dwarfs from the CARMENES survey, and although this approach improved the estimation of $\textit{T}_{\rm eff}$ and [M/H] for M dwarfs from high-resolution spectra obtained with CARMENES, the lack of sufficiently large number of reference stars to transfer knowledge is a limitation for the technique. If the reference dataset is limited in size, diversity, or representation across the parameter space, the models may not generalise well to a broader range of M dwarfs.

In this work, we present a novel transfer learning approach for estimating photospheric parameters in M dwarfs based on their stellar spectra. The primary goal of the proposed method is to address the aforementioned limitation identified by \citetalias{bello2023} by eliminating the requirement for interferometric values in the knowledge transfer process.
To achieve this, instead of employing a model-based transfer learning approach, as in \citetalias{bello2023}, where the transferred knowledge is encoded into model parameters, priors or model architectures, we propose a feature-based transfer learning. In this approach, the knowledge to be transferred can be considered as the learned feature representation. The idea is to learn a `good' feature representation so that, by projecting data onto the new representation, the differences between domains (source and target, i.e. synthetic and observed spectra in our case) can be reduced. This allows the source domain labelled data (synthetic spectra with known parameters) to be used to train a precise model for the target domain constituted by the observed spectra \citep{yang2020}.

% In Section \ref{acs_sec:data}, we provide details on the CARMENES sample and the PHOENIX-ACES synthetic model grid used in this study. The proposed methodology, based on autoencoders and transfer learning, is outlined in Section \ref{acs_sec:methodology}. The derived stellar atmospheric parameters are then analysed and compared with existing literature in Section \ref{acs_sec:results}. Finally, Section \ref{acs_sec:conclusions} summarises the main conclusions of this work.


%--------------------------------------------------------------------

\section{Data} \label{acs_sec:data}

The proposed approach was tested using the same sample spectra as \citetalias{pass2019}. This sample, listed in their Table B.1, comprise 282 M dwarfs observed with CARMENES. Additionally, four more stars from an independent interferometric sample, as described by \citetalias{bello2023}, were included.

CARMENES is installed at the Calar Alto Observatory, located in Spain, and stands as one of the leading instruments in the quest for searching for Earth-like planets within the habitable zones around M dwarfs. It comprises two separate spectrographs: one for the visible (VIS) wavelength range (from 520 to 960\,nm) and the other for the near-infrared (NIR) range (from 960 to 1710\,nm), each offering high-spectral resolutions of R\,$\approx$\,94\,600 and 80\,500, respectively \citep{Quirrenbach20,reiners2018}.

A detailed description of the data reduction procedure is available in \citet{Zechmeister14}, \citet{Caballero2016}, and \citetalias{pass2019}.
Similar to the latter, we used a high signal-to-noise (S/N) template spectra for each star. These templates are generated as byproducts of the CARMENES radial-velocity pipeline, known as {\tt serval}
\citep[SpEctrum Radial Velocity AnaLyser;][]{Zechmeister2018}. In the standard data flow, the code constructs a template for each target star from a minimum of five individual spectra to derive the radial velocities through least-square fitting to the template.
The S/N of the observed CARMENES sample used in this work was above 150. Concerning the wavelength window, we adopted the range 8\,800--8\,835\,\AA, consistent with \citetalias{bello2023}, as this window displayed the smallest mean squared error among all the investigated windows in \citetalias{pass20}.

To train the neural network models, we utilised the PHOENIX-ACES spectra library\footnote{\url{https://phoenix.astro.physik.uni-goettingen.de/}} \citep{Husser2013}. This library is chosen for its consideration of spectral features present in cool dwarfs. Furthermore, the use of synthetic models enables the generation of a large number of spectra with known parameters, eliminating the need for limited samples of observations with well-known stellar parameters. We used the same PHOENIX-ACES grid as in previous works (\citetalias{pass20}; \citetalias{bello2023}), which was generated by linearly interpolating between the existing grid points using {\ttfamily pyterpol} \citep{Nemravov2016}. The complete dataset contains a grid of 449\,806 synthetic high-resolution spectra between 8\,800\,{\AA} and 8\,835\,{\AA} with $\textit{T}_{\rm eff}$ between 2\,300 and 4\,500\,K (step 25\,K), log \textit{g} between 4.2 and 5.5\,dex (step 0.1\,dex), [M/H] between -1.0 and 0.8\,dex (step 0.1\,dex), and $\textit{v}\sin{i}$ between 1.5 and 60.0\,km\,s$^{-1}$ (with a variable step of 0.5, 1.0, 2.0 or 5.0; see Table 1 in \citetalias{pass20}). A degeneracy between $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] was described by \citet{pass18}, who found exceptionally high values of log \textit{g} and [Fe/H] for well-fitting PHOENIX-ACES models. This degeneracy was further underscored by \citetalias{pass2019} and \citetalias{pass20} during the application of DL models to the observed CARMENES spectra, and the latter imposed additional constraints to the grid leveraging the PARSEC v1.2S evolutionary models \citep{parsec2012,Chen2014,Chen2015,Tang2014}. Degeneracies between stellar parameters are often found when fitting synthetic spectra, and some authors have explored several ways to help break them \citep{buzzoni2001,brewer2015}. The refinement performed by \citetalias{pass20} aimed to exclude parameter combinations for M dwarfs that do not fit the main sequence, as discussed in Section 4.2 of their work. Notably, \citetalias{pass20} demonstrated that the imposition of these constraints on the synthetic model grid used in the training of the DL models is capable of breaking the observed parameter degeneracy. After applying these restrictions, the grid includes 22\,933 PHOENIX-ACES spectra.

Due to the negligible presence of telluric features in the investigated range, telluric correction was not applied to the VIS spectra.
For normalisation, we employed the Gaussian Inflection Spline Interpolation Continuum ({\tt GISIC}\footnote{\url{https://pypi.org/project/GISIC/}}), the same method and routine used by \citetalias{pass20} and developed by D.\,D.~Whitten, designed for spectra with strong molecular features.
Following the same approach as \citetalias{bello2023}, we applied this procedure to both observed and synthetic spectra within the spectral window 8800--8835\,\AA{} with an additional 5\,\AA{} on each side to mitigate potential edge effects. Moreover, the observed spectra underwent radial velocity correction to align with the rest frame of the synthetic spectra, achieved through cross-correlation \citep[\texttt{crosscorrRV} from PyAstronomy,][]{Czesla2019} between a PHOENIX model spectrum and the observed spectrum. To ensure a universal wavelength grid, essential for applying the proposed method, the wavelength grid of the observed spectra was linearly interpolated with the grid of the synthetic spectra.

In spite of the performed spectra preparation, differences in the feature distributions of the synthetic and observed sets of spectra (i.e. synthetic gap) were identified. We used the Uniform Manifold Approximation and Projection \citep[UMAP;][]{McInnes2018}, with a metric that considers the correlation between the spectra, to project the high-dimensional input space (3\,500 flux values for each spectrum) into a two-dimensional space while preserving inter-distances. As shown in Fig. \ref{fig:umap_flux}, akin to \citetalias{pass20} and \citetalias{bello2023}, most of the CARMENES spectra (grey triangles) do not align precisely within the synthetic spectra (colour-coded dots). Thus, a transfer learning approach appears appropriate to extend the applicability of the regression models trained with the synthetic spectra to the observed spectra.

%--------------------------------------------------------------------


\section{Methodology} \label{acs_sec:methodology}

The DTL approach proposed in this paper can be summarised as follows. Initially, we extract a low-dimensional representation of synthetic spectra based on the PHOENIX-ACES library using autoencoders (AEs), a special kind of neural network initially proposed for dimensionality reduction \citep{hinton2006b}. Then, the knowledge transfer process is performed by fine-tuning these AEs with high-resolution spectra observed with the CARMENES instrument. It must be noted that no stellar parameters were used during this re-training. With the low-dimensional representations of the synthetic spectra resulting from the initial step, we trained CNNs. Finally, using these CNNs, we estimated the stellar parameters ($\textit{T}_{\rm eff}$, log \textit{g}, [M/H], and $\textit{v}\sin{i}$) for 286 CARMENES M dwarfs by using their low-dimensional representations obtained after the fine-tuning step.

\subsection{Feature extraction using an autoencoder} \label{acs_sec:ac}

In this study, we explore unsupervised feature extraction from stellar spectra using AEs to facilitate feature-based transfer learning and leverage the new representations for estimating photospheric parameters.
Belonging to representation learning --a subfield of machine learning--, AEs have the capability to capture the underlying factors hidden in the observed data \citep{Bengio13,Goodfellow16}.
They have been succesfully used in various astrophysical applications, including unsupervised feature learning from galaxy spectral energy distribution \citep{FronteraPons17}, learning of non-linear representations from rest-frame spectroscopic data for redshift estimation \citep{FronteraPons19}, galaxy classification \citep{Cheng21}, astrophysical component separation \citep{Milosevic21}, reconstruction of missing magnitudes from observed objects before classifying them into stars, galaxies, and quasars \citep{Khramtsov21}, and telluric correction \citep{Kjarsgaard23}.
In addition, some authors have used AEs to estimate stellar atmospheric parameters from spectra \citep{Yang2015,Li2017}. However, their approach is different from our proposal since the training of the models was performed in a supervised manner: spectra from SDSS/SEGUE DR7 \citep{Abazajian2009} were used, and $\textit{T}_{\rm eff}$, log \textit{g}, and [Fe/H] were obtained from the SDSS/SEGUE Spectroscopic Parameter Pipeline \citep[SSPP;][]{SSPP01,SSPP02,SSPP03,SSPP04} for stars in the temperature range 4\,088-9\,747\,K (earlier than our CARMENES targets).
In our case, we are interested in the use of AEs to enable transfer learning, as representation learning enables the transfer of knowledge when there are features useful for different settings or tasks that correspond to underlying factors appearing in more than one setting \citep{Goodfellow16}.

The rationale behind the first step of our methodology is to find a meaningful low-dimensional representation, referred to as the latent space, of the synthetic spectra. To accomplish this, we employed an AE, which consists of an `encoder' trained to transform the high-dimensional spectrum into a low-dimensional code, and a `decoder' trained to reconstruct the original spectrum as accurate as possible from its lower-dimensional latent space (see Fig. \ref{fig:ac_info}).

First, we divided the grid of synthetic spectra into a training set (70\,\%) and a test set (30\,\%). We considered multiple AE architectures, developing a python code to create a flexible AE structure. The number of neurons on each layer, the L1 regularisation term for the dense layers (used to prevent overfitting), and the learning rate for the Adam optimisation \citep[a computationally efficient stochastic gradient descent method,][]{adam} were passed as parameters. For this code, we relied on the \texttt{Keras}\footnote{\url{https://keras.io/about/}} \citep{keras} deep learning API, which runs on top of the \texttt{Tensorflow}\footnote{\url{https://www.tensorflow.org/}} \citep{tensorflow} machine learning platform. Next, we created a grid for these hyperparameters and performed an exhaustive search using the \texttt{GridSearchCV} class from the \texttt{scikit-learn}\footnote{\url{https://scikit-learn.org/stable/}} package, which optimises the hyperparameters of an estimator through k-fold cross-validation, using any scoring metric to evaluate the model. In our case, we used 4-fold cross-validation and the mean squared error between the reconstructed and the original validation data as the scoring metric. To integrate our python code into a \texttt{scikit-learn} workflow, we used the \texttt{KerasRegressor} wrapper from the \texttt{scikeras}\footnote{\url{https://adriangb.com/scikeras/stable/}} python package.

After this search for the best hyperparameter combinations, we only kept those with a mean cross-validation score below the median, evaluated using the entire grid. We trained an AE for each of these architectures, adding a contractive regularisation term in the loss function, consisting of the squared Frobenius norm of the Jacobian matrix of the encoder activations with respect to the input:

\begin{equation}
    \left \|\,J_{f}\,(x)\, \right \|_{F}^{2}=\sum_{ij}\left ( \frac{\partial h_{j}\,(x)}{\partial x_i} \right)^2,
	\label{eq:contractive_loss}
\end{equation}

\noindent where $f$ represents the encoding function that maps the input $x$ to the hidden representation $h$. The main idea of contractive AEs is to make the feature extraction more robust to small perturbations in the training data. In the overall loss function optimisation, the trade-off between the reconstruction and the L1 regularisation terms will retain the important variations in the latent space for the reconstruction of the input \citep{rifai2011}.

We only kept the AEs with a learning rate equal to 0.0001, as we found that some of them with a higher learning rate were not able to converge properly, leading to a poor latent representation of the spectra. With this, we ended up with 26 final AE architectures and evaluated them on the test set, obtaining mean squared reconstruction errors $\sim 5\cdot10^{-5}$. Fig. \ref{fig:ph_rec} shows the reconstruction and the latent space of a PHOENIX-ACES synthetic spectrum for one of the AEs. Using the encoder networks of the AEs, we obtained 26 sets (one for each AE) of 32-dimensional compressed representations for the grid of synthetic spectra.


\subsection{Deep transfer learning} \label{acs_sec:dtl}

The dependence of DL algorithms on massive training data is a crucial hurdle to overcome when a research scenario requires labelled data. In some fields, such as astrophysics, building a large, annotated data set can be incredibly complex and expensive. A straightforward and widely used solution to this problem is the use of synthetic data to train the DL models, but this may include a systematic error in the methodology if the synthetic gap (see Section \ref{acs_sec:data}) is significant, as is the case in this work.

Transfer learning (TL) plays a key role in solving the above problems, as it allows knowledge to be transferred from a rich source domain to a related but not identical target domain. The transition from TL to DTL, with incomplete DTL as an intermediate stage \citep[deep neural networks are only used as feature extractors in TL models;][]{yu2022}, came with the integration of DL techniques into the TL paradigm.

In the context of TL, a domain can be represented as $D=\left \{\mathcal{X},P(X)  \right \}$, where $\mathcal{X}$ denotes a feature space and $P(X)$ represents the marginal probability distribution for $X=\left \{x_1,...,x_n \right \} \in \mathcal{X}$. Also,  a task can be represented as $T=\left \{Y, f(\cdot) \right \}$, where $Y$ denotes a label space and $f(\cdot)$ is a predictive function. According to the definition provided by \citet{pan2010}, given a source domain $D_{\rm S}$ and task $T_{\mathrm{S}}$, and a target domain $D_{\mathrm{T}}$ and task $T_{\mathrm{T}}$, TL aims to enhance the performance of a predictive function $f_{\mathrm{T}}(\cdot)$ in $D_{\mathrm{T}}$, using the knowledge available in $D_{\mathrm{S}}$ and $T_{\mathrm{S}}$, where $D_{\mathrm{S}}\neq D_{\mathrm{T}}$ and/or $T_{\mathrm{S}}\neq T_{\mathrm{T}}$. In our work, the source domain is represented by the grid of synthetic PHOENIX-ACES spectra, while the target domain is built from the 286 CARMENES observed spectra. Moreover, the predictive function is defined as the encoder network of the AE architecture, responsible for compressing the input spectra into the low-dimensional latent representation.

The purpose of this step in the methodology is to adopt a DTL-based strategy, in particular the fine-tuning approach \citep{brian2016,yosinski2014}, using the AE architectures we already trained in the source domain to obtain a meaningful low-dimensional latent representation of our data-poor target domain. In this process, we kept the weights frozen in all encoder layers until the last one, leaving only the deepest encoder layer, the bottleneck (i.e. the latent space or compressed representation of the spectrum, as illustrated in Fig. \ref{fig:ac_info}), and the decoder network to be re-trained. The motivation for keeping the lower layers frozen is to prevent generic learning from being overwritten, thus preserving the knowledge acquired by the network to recognise relevant spectral features, while the more specific features are tailored to the target domain \citep{sadr2020}.

\citet{pan2018} already explored the possibility of finding a low-dimensional latent space in which source and domain data are close to each other, and using it as a bridge to transfer the knowledge from the labelled source domain to the unlabelled target domain. In our case, the ultimate goal of this process is to find a low-dimensional representation of the observed spectra that is closer to the synthetic latent representation than in the initial high-dimensional space of the spectra (see Fig. \ref{fig:umap_flux}). Furthermore, we want for these target representations to be as meaningful as possible, since we intend to use them later as a starting point for estimating the stellar parameters.

First, we divided the target set of 286 CARMENES spectra into a training set (80\,\%) and a test set (20\,\%), with the latter being used to assess the reconstruction error across the target domain. Then, we fine-tuned the 26 AE architectures, following the process explained above, obtaining mean squared reconstruction errors $\sim4\cdot 10^{-4}$ on the test set, in contrast to the reconstruction errors ($\sim3\cdot 10^{-3}$) obtained on the CARMENES set using the AEs pre-trained on the PHOENIX-ACES spectra. It must be noted that no stellar parameters were used during this re-training.

Fig. \ref{fig:vsdtl} illustrates the importance of this step for the AE to effectively adapt to our specific target domain, ensuring that the compressed representations provided by the fine-tuned encoders will be more meaningful than those we would have obtained with the initial training. Using these fine-tuned encoder networks, we obtained the final 26 sets of 32-dimensional representations for the observed CARMENES spectra.


While our goal was to preserve the meaningfulness of the low-dimensional representations of the synthetic and observed spectra, we aimed, above all, to minimise the disparity between the observed and synthetic compressed representations. For instance, Fig. \ref{fig:umap_enc} illustrates a UMAP two-dimensional projection, using the same metric as in Fig. \ref{fig:umap_flux}, for one of the 26 sets of PHOENIX-ACES and CARMENES representations. In contrast to Fig. \ref{fig:umap_flux}, in this case, the CARMENES objects are integrated over the space occupied by the PHOENIX-ACES family of projections, leading to a significant reduction of the differences in feature distributions between the two domains. Consequently, we calculated the minimum Euclidean distance from each CARMENES instance to the synthetic grid in both the initial high-dimensional space and the new low-dimensional feature space. While the mean distance is $2.72$ when evaluated in the initial feature space (Fig. \ref{fig:umap_flux}), it is reduced to a mean value of $0.086$ for the encoded representations (Fig. \ref{fig:umap_enc}), averaged over the 26 sets.
In this manner, a latent space that encodes the shared knowledge from both domains was learned, effectively bridging the gap between them.


\subsection{Stellar parameter estimation} \label{acs_sec:cnn}

In the final step of our methodology, we employed CNNs, one of the oldest deep learning approaches \citep{lecun1998}, to estimate the stellar parameters of the 286 CARMENES stars. As a starting point for this process, we used the 26 sets of encoded representations for the PHOENIX-ACES and CARMENES spectra obtained in the previous steps of our work.

Inspired by the hierarchical structure of the human visual nervous system \citep[a precursor of CNNs; ][]{necognitron1980}, CNNs are therefore generally used to deal with image data. They are a specific class of multilayered feedforward neural networks, initially developed for image classification and visual pattern recognisition \citep{lecun1998,alexnet2012,vggnet2014}. The distinctive factor of CNNs is the use of convolution operations, in the convolutional layers, to automatically extract features from data. After the convolutional structure, the set of features is flattened and passed to an artificial neural network (ANN) to perform the classification or regression task.

In each forward-propagation process, the input of each neuron of the convolutional layer is obtained with an element-wise dot product between a convolution kernel (or filter), with trainable coefficients, and the outputs of the previous layer. The resulting arrays and a tunable bias are added up and passed through an activation function to obtain the output feature map of the neuron. The set of kernels is tuned during the training process, as the weights of the deep ANN layers are adjusted, so that the different feature maps of the layer represent specific features detected in the input data. \citet{surveycnn} provided a detailed review of CNNs.

In one-dimensional (1D) CNNs (see Fig. \ref{fig:cnn}), the convolution kernel slides along a sequence of non-independent values to extract relevant features, and they have proven to be highly performant in several applications during the recent years \citep{kiranyaz2019}. \citet{sharma2020} presented a semisupervised learning approach to handle the scarcity of labelled samples, using AE and 1D CNN architectures for stellar spectral classification. \citet{zheng2020} explored how the generation of stellar spectra to balance the training data set can significantly improve the performance of a 1D CNN classifier.


Since we used 32-component vectors as input data for the stellar parameter estimation, we built a 1D CNN architecture. This architecture consists of two convolutional layers (Conv1D) with a variable number of filters (see Table \ref{tab:cnn_arc}), followed by four fully-connected (Dense) layers. A flattening step is incorporated between the convolutional and the ANN components to reshape the output of the final convolutional layer (number of outputs $\times$ number of filters) into a one-dimensional vector. This vector is then fed into the dense layers. We used a rectified linear unit (ReLU) activation function in all layers except the output layer, with a linear activation. We estimated $\textit{T}_{\rm eff}$, log\,$\textit{g}$, [M/H], and $\textit{v}\sin{i}$ independently, searching for the optimal hyperparameters of the 1D CNN architecture (same procedure as in Section \ref{acs_sec:ac}) in the estimation of each parameter. Table \ref{tab:cnn_arc} describes in detail the CNN architectures used. We followed the same procedure in the independent estimation of the different stellar parameters. To have a significant number of final estimates and to assess the robustness of our methodology, we built five CNN models for each of the 26 sets of encoded representations, thus obtaining a total of 130 regressors for each of the parameters.

To train the CNN models, we use stratified sampling to create the indices of the traning (70\,\%) and test (30\,\%) sets from the PHOENIX-ACES low-dimensional representations, ensuring that the distribution of the target parameter is representative of the overall distribution in both sets. For this, we relied on the \texttt{StratifiedShuffleSplit} class of the \texttt{scikit-learn} python package, which automatically performs stratification based on a target variable and generates indices to split data into training and test set. We trained the CNN models using the synthetic compressed representations, with a mean squared error loss function, and evaluated them on the test set. As final regressors, we kept the 80 models with the lowest mean squared error in the test set, obtaining an upper value of 353\,K, 0.0042\,dex, 0.0016\,dex, and 0.054\,km\,s$^{-1}$ for $\textit{T}_{\rm eff}$, log\,$\textit{g}$, [M/H], and $\textit{v}\sin{i}$, respectively. Using these models, we obtained 80 final parameter estimates for each of the CARMENES stars.

We followed the same strategy used by \citetalias{pass20} and \citetalias{bello2023} for the uncertainty estimation of the stellar parameters. For each star, we gathered the 80 estimations and approximated the probability density function using the Kernel Density Estimate \citep[KDE; ][]{chen1997, poggio2021} technique. We took the maximum of this probability density function as the confident estimation for the stellar parameter, together with the 1$\sigma$ thresholds as the corresponding uncertainties. Here, the final stellar parameter is derived from a distribution of parameter estimates which come from 26 different sets of input features, together with the five CNN models built for each set. Therefore, the uncertainties provided should be understood as an intrinsic error of our methodology. Fig. \ref{fig:kde_plots} shows an example of the results for a single star.


%--------------------------------------------------------------------


\section{Results and discussion} \label{acs_sec:results}

\subsection{Stellar parameters analysis} \label{acs_sec:par_analysis}


Table \ref{tab:pars} presents the stellar atmospheric parameters determined with our methodology. The top left panel in Fig. \ref{fig:par_diags} shows a Kiel diagram that relates all our estimated parameters, along with isochrones based on the  PAdova and TRieste Stellar Evolution Code \citep[PARSEC release v1.2S;][]{parsec2012} for 5\,Gyr and [M/H] $=-0.4, 0.0,$ and $0.1$\,dex. The results obtained with our methodology follow the trend set by the isochrones and the structure observed in the estimated metallicities is also consistent with them. The remaining three panels in Fig. \ref{fig:par_diags} show a Hertzsprung-Russell diagram (HRD) of our results, with different features highlighted in each of them. We computed the bolometric luminosities, $\textit{L}_{\mathrm{bol}}$, as \citet{cifuentes2020} using the latest astrometry and photometry from {\it Gaia} DR3 \citep{gaiadr3}. Theoretical isochrones, for solar metallicity, from PARSEC v1.2S and from evolutionary models presented by \citet{baraffe2015} are overplotted in the top right panel for 0.1 and 5\,Gyr. Both the Kiel diagram and the HRD reveal a clear outlier region at the lowest temperatures \citep[mid M-dwarf regime;][]{cifuentes2020,pecaut2013}, populated mostly by the stars with a high estimated projected rotational velocity ($\textit{v}\sin{i}$). These fast rotators in our sample are located at the expected M-dwarf regime, following the relation between the spectral types from the CARMENES input catalogue \citep[Carmencita; ][]{alonsofloriano2015,caballero2016a} and the $\textit{v}\sin{i}$ values calculated by \citet{reiners2018} \citepalias[see Fig. 2 in][]{mar21}.

The bottom panels in Fig. \ref{fig:par_diags} help to understand the outliers that deviate from the main sequence. The bottom left panel shows that almost all the overluminuous outliers in the HRD are identified as H$\alpha$ active stars by \citet{schofer2019}, considered as such if the pseudo-EW of the H$\alpha$ line satisfies pEW$'$(H$\alpha)<-0.3$\,\AA~(H$\alpha$ flag from Table B.1 in \citetalias{mar21}). As found in previous works \citep[e.g. ][]{jeffers2018,reiners2018}, the fraction of H$\alpha$ active stars is higher at later spectral types. There are clear patterns in the HRD which arise from the kinematic membership of the targets. For instance, and in agreement with \citet{jeffers2018}, most H$\alpha$ active and rapidly rotating stars are kinematically young (dots marked with a + in the bottom right panel).

To study the possible membership of our sample to nearby young stellar associatons, we relied on \texttt{BANYAN}~$\Sigma$\footnote{\url{http://www.exoplanetes.umontreal.ca/banyan/}} \citep{banyan}, a Bayesian analysis tool to identify members of young associations. Modelled with multivariate Gaussians in six-dimensional $\rm XYZUVW$ space, \texttt{BANYAN}~$\Sigma$ can derive membership probabilities for all known and well-characterised young associations within 150\,pc. In our case, we used the python version of \texttt{BANYAN}~$\Sigma$\footnote{\url{https://github.com/jgagneastro/banyan_sigma}}, and included the \textit{Gaia} DR3 sky coordinates, proper motion, radial velocity, and parallax of our target stars as input parameters to the algorithm. The classifier gave a high probability (>80\,\%) for 9 objects to belong to a young stellar association, in 7 of the cases with a probability greater than 95\,\%. Table \ref{tab:young} lists the details of these objects. All these stars with a possible membership in a young stellar associaton are represented with a thick open circle in the bottom right panel of Fig. \ref{fig:par_diags}. Here, we also considered four extra stars, namely J09133+688 (G\,234-057), J12156+526 (StKM\,2-809), J15218+209 (GJ\,9520), and J18174+483 (TYC\,3529-1437-1), which \citetalias{schw19} mentioned as young age-based outliers.

The bottom left panel in Fig. \ref{fig:par_diags} shows that outliers below the main sequence are typically members of the thick disc Galactic population \citep[Cortés-Contreras et al., in prep.; ][]{tesis_miriam}. Furthermore, four of these outliers are reported to have a behaviour akin to subdwarfs (empty squares in top and bottom left panels) both by \citetalias{mar21} and \citetalias{schw19}. Table \ref{tab:subd} details all the outliers we identified with low-metallicity behaviour, along with the metallicity estimations found in the literature. As discussed by \citet{jao2008}, with the decrease in the metallicity of these objects the TiO opacity also strongly decreases, and this less blanketing from the TiO bands causes more continuum flux to radiate from the deeper and hotter layer of the stellar atmosphere, so that these stars appear bluer than their solar metallicity counterparts (see Fig. 1 in \citealt{jao2008}). Our [M/H] determinations for these stars are, in general, in good agreement with the literature.

Fig. \ref{fig:pop_mh_hist} shows the distribution of our predicted metallicities broken down by kinematic membership in the thick disc (TD), thick disc-thin disc transition (TD-D), thin disc (D), and young disc (YD) Galactic populations \citep[Cortés-Contreras et al., in prep.; ][]{tesis_miriam}. This breakdown reveals the distinction between metal-rich thin disc stars and metal-poor stars in the older thick disc \citep{bensby2005,gaiamh2023}, with the TD-D transition as an intermediate step. To prove this, we performed a two-sample Kolmogorov-Smirnov test \citep{kolmogorov33,smirnov48} on the thin and thick disc samples, which returned a $p\,\rm{value} = 0.0071$, rejecting the hypothesis that both samples come from the same distribution.

Also, the 2MASS-\textit{Gaia} $\textit{G}_{\mathrm{BP}} - \textit{G}_{\mathrm{RP}}$ versus $\textit{G}-\textit{J}$ colour-colour diagram in Fig. \ref{fig:col_diag} shows how the evolution in our estimated effective temperatures is coherent with the colour-colour relationship (see Fig. 14 in \citealt{cifuentes2020}). For this diagram, we only considered stars with reliable 2MASS $J$-band and \textit{Gaia} DR3 $\textit{G}_{\mathrm{BP}}$ and $\textit{G}_{\mathrm{RP}}$ photometry.

%--------------------------------------------------------------------



\subsection{Comparison with the literature}
\label{acs_sec:lit_comp}

We compared our results with different collections found in the literature. Whereas this section focuses on the latest studies using CARMENES data, namely \citetalias{bello2023}, \citetalias{mar21}, \citetalias{pass2019}, \citetalias{pass20}, and \citetalias{schw19}, a more extensive compilation of literature, together with the uncertainties of the estimations, is provided in Appendix \ref{app:appb_lit}. For \citetalias{pass2019}, we considered the parameters derived from VIS spectra. Table \ref{tab:comparison_lit} lists the mean difference ($\overline{\Delta}$; literature$-$this work), root mean squared error (rmse), and Pearson correlation coefficient ($r_{\rm p}$) for the comparison with each of the literature collections. An interactive version of the results presented in this section is available to the astronomical community\,\footnote{\url{https://cab.inta-csic.es/users/pmas/}}.


Figure~\ref{fig:scatter_teff} depicts the comparison with literature values for $\textit{T}_{\rm eff}$. The left panels show a similar linear trend among \citetalias{mar21}, \citetalias{pass2019}, and \citetalias{schw19} with our values, all of them with a slope of less than one, for the region $\textit{T}_{\rm eff}$ (this work) $\lesssim 3\,750$\,K. From this value onwards, where the number of stars in our training set is smaller, the dispersion increases significantly and our $\textit{T}_{\rm eff}$ estimations deviate towards hotter values, resulting in a mean difference of $\overline{\Delta}=-19$\,K, $\overline{\Delta}=-80$\,K, $\overline{\Delta}=-40$\,K for \citetalias{mar21}, \citetalias{pass2019}, and \citetalias{schw19}, respectively. The figures provided in Appendix \ref{app:appb_lit} show that the uncertainties intrinsic to our methodology are also larger for estimations above 3\,750\,K. The right panels show how the agreement with the values obtained following the approach described by \citetalias{pass20} is excellent, which is expected since their methodology is the closest to the one presented in this work. Moreover, the comparison with the results from \citetalias{bello2023} reveals the same structure, but inverted, as shown in Fig. 9 of their work, with a larger dispersion than that observed for the other literature collections. The black stars in the top right panel represent the 14 interferometrically derived $\textit{T}_{\rm eff}$ values (see Table 1 in \citetalias{bello2023}), which are on average cooler than the temperatures obtained with our methodology ($\overline{\Delta}_{\rm interf}=-119$\,K). The $r_{\rm p}$ values listed in Table~\ref{tab:comparison_lit} show a strong correlation with all the collections.

Figure \ref{fig:scatter_logg} shows a similar literature comparison for log\,$\textit{g}$. For \citetalias{schw19}, we considered the values derived using their mass-radius relation and the Stefan-Boltzmann's law. The log\,$\textit{g}$ values from \citetalias{mar21} show a large dispersion ($r_{\rm p}=0.39$), as already mentioned in their work, and are generally spread towards higher values ($\overline{\Delta}=0.12$\,dex). While the results from \citetalias{pass2019} cover the same range and are similar on average to our obtained log\,$\textit{g}$ ($\overline{\Delta}=0.00$\,dex), those from \citetalias{schw19} extend to higher values and are on average higher than ours ($\overline{\Delta}=0.13$\,dex). It should be noted that, while \citetalias{pass2019} and \citetalias{schw19} fix log\,$\textit{g}$ using theoretical isochrones, \citetalias{mar21} has log\,$\textit{g}$ as a free parameter.
Moreover, our results show a good correlation ($r_{\rm p}=0.93$) with those obtained following the methodology described by \citetalias{pass20}, although the latter are deviated to lower values ($\overline{\Delta}=-0.04$\,dex).

As discussed in \citet{passegger2022}, several discrepancies can be found when comparing metallicities of M dwarfs obtained with different methodologies. Figure \ref{fig:scatter_mh} shows the comparison with literature values for our [M/H] estimations, which directly translate into [Fe/H] values \citep{pass20,passegger2022}. For \citetalias{mar21}, we considered the values corrected for alpha enhancement. Our results are similar on average to those from \citetalias{schw19} ($\overline{\Delta}=0.00$\,dex), while \citetalias{pass2019} and \citetalias{mar21} results tend to be higher and lower, with $\overline{\Delta}=0.06$ and $\overline{\Delta}=-0.11$\,dex, respectively. As already mentioned in \citet{passegger2022}, the results from the DL methodology described by \citetalias{pass20} are deviated towards more metal-rich values, with $\overline{\Delta}=0.23$\,dex. We note that this deviation, which is attributed to the synthetic gap by \citetalias{pass20}, does not appear in the DTL methodologies presented by \citetalias{bello2023} and here. \citetalias{bello2023} metallicities cover more or less the same range as our results, and the spectroscopically determined [M/H] values from FGK+M systems (see Table 3 in \citetalias{bello2023}) (black stars in the top right panel) are systematically lower ($\overline{\Delta}=-0.13$\,dex).

We also compared our $\textit{v}\sin{i}$ determinations with the ones derived by \citet{reiners2018} using the cross-correlation method and with those obtained following the DL methodology described by \citetalias{pass20}. Fig. \ref{fig:scatter_vsini} shows how our derived $\textit{v}\sin{i}$ are mostly consistent with the literature within their errors. Both \citetalias{pass20} and \citet{reiners2018} results show a good correlation with our values ($r_{\rm p}=0.99$ and 0.98, respectively). Since most of the objects are located at lower $\textit{v}\sin{i}$ values, it is convenient to split the analysis provided in Table \ref{tab:comparison_lit} at a cut-off value of $v\sin{i}\,{\rm (this\,work)}=12$\,km\,s$^{-1}$. Below this value, \citetalias{pass20} presents $\overline{\Delta}=1.83$\,km\,s$^{-1}$ and ${\rm rmse}=1.97$\,km\,s$^{-1}$, with $\overline{\Delta}=-1.22$\,km\,s$^{-1}$ and ${\rm rmse}=1.45$\,km\,s$^{-1}$ for faster rotators. Similarly, for \citet{reiners2018}, we obtained $\overline{\Delta}=-0.68$\,km\,s$^{-1}$ and ${\rm rmse}=1.24$\,km\,s$^{-1}$ for values below the threshold, and $\overline{\Delta}=-3.47$\,km\,s$^{-1}$ and ${\rm rmse}=3.71$\,km\,s$^{-1}$ for values above.


%--------------------------------------------------------------------


\section{Conclusions}\label{acs_sec:conclusions}

This work serves as an extension of a series of papers (\citetalias{pass20}; \citetalias{bello2023}) dedicated to exploring the use of DL for stellar parameter estimation of CARMENES M dwarfs, based on synthetic spectra. \citetalias{bello2023} developed a model-based DTL technique to bridge the significant differences in flux features between the two spectral families, reported by \citetalias{pass20}. Here, we propose a parallel feature-based DTL strategy that addresses the limitations mentioned in their work regarding the need for high-quality stellar parameter estimations in the knowledge transfer process.

Using a methodology that combines the use of AEs and CNNs, we derived new estimations for the stellar parameters $\textit{T}_{\rm eff}$, log\,$\textit{g}$, [M/H], and $\textit{v}\sin{i}$ of 286 M dwarfs observed with CARMENES. The AE models were trained on PHOENIX-ACES synthetic spectra and then fine-tuned using the CARMENES high-S/N, high-resolution spectra. In the fine-tuning process, no data other than the observed spectra are required, which gives our methodology great flexibility, as no measured stellar parameters are involved in the knowledge transfer. We used the low-dimensional representations of the synthetic and observed spectra, resulting from the initial training and the fine-tuning steps, respectively, as input to the CNNs for the estimation of the stellar parameters. In this way, parameter estimation is conducted using a dataset in which no significant differences in the feature distributions between the synthetic and observed data are evident.

We performed an in-depth analysis of our estimated stellar parameters, using the diagram shown in Fig. \ref{fig:par_diags} to study the objects that deviate from the main sequence. We found that almost all the overlumimuous outliers are identified as H$\alpha$ active stars by \citet{schofer2019}, while outliers located below the main sequence are typically metal-poor stars from the thick disc Galactic population. In particular, using the \texttt{BANYAN}~$\Sigma$ tool, we found 9 objects with a high Bayesian probability of belonging to five different young stellar associations, in 7 of these cases with a probability of more than 95\,\%. Together with the low-metallicity objects already reported in \citetalias{mar21} and \citetalias{schw19}, we identified eight more stars that exhibit the same behaviour.

We also conducted a comparative study between our results and the latest studies using CARMENES data, finding good consistency with the literature in most cases. Both our $\textit{T}_{\rm eff}$ and log\,$\textit{g}$ determinations are, in general, strongly correlated with the results from the literature, with a systematic deviation in our $\textit{T}_{\rm eff}$ scale towards hotter values for estimations above 3\,750\,K. As expected, our parameter determinations are in very good agreement with \citetalias{pass20}, since their methodology is the most similar to the one presented in this paper. More importantly, the deviation in metallicity attributed to the synthetic gap in their work is not observed in ours thanks to the DTL approach. This, together with the work presented by \citetalias{bello2023}, demonstrates the great potential of DTL-based strategies to bridge the synthetic gap in stellar parameter estimation from synthetic spectra.

%-------------------------------------------------------------------

%************************************************
\chapter{Characterisation of Ultracool Dwarfs with Deep Transfer Learning} \label{chp:dtl_ucds}

The future is bright for the field of ultracool dwarfs. The Visible Instrument (VIS) and the Near-Infrared Spectrometer and Photometer (NISP) aboard the ESA \textit{Euclid} mission will provide a unique combination of wide-area ($\sim15\,000$\,deg$^2$) coverage, high-spatial resolution, and unprecedented sensitivity, with a low-resolution near-infrared spectroscopic survey that will enable the spectral characterisation of a huge number of previously undiscovered ultracool dwarfs. This was recently demonstrated by \citet{jerry2024}, who highlighted the reliability that the data provided by the slitless spectroscopic mode of the NISP instrument will deliver for the spectral characterisation of ultracool dwarfs in both the deep and wide surveys. In the summer of 2027, the NASA Nancy Grace Roman Space Telescope will join Euclid to explore the infrared sky as never before possible, with a much deeper and more precise core survey, but over a smaller area ($\sim2\,000$\,deg$^2$). These surveys will be complemented in the optical by the LSST, carried out in the Vera C. Rubin Observatory, expected to start operations in mid-2025. The LSST will provide a high-spatial resolution, high-cadence, and high-sensitivity multi-band photometric survey over the entire Southern Hemisphere sky, that will supersede the previous SDSS and Pan-STARRS optical datasets. The combination of all these upcoming surveys will lead to a quantum leap of over an order of magnitude in the number of ultracool dwarfs detected \citep{solano2021,martin2023}, enabling the study of more distant ultracool dwarf populations than ever before.

The low-resolution near-infrared spectroscopic survey conducted by \textit{Euclid} represents a key opportunity for developing a flexible, automated, and reliable methodology capable of harnessing these vast amounts of data to spectroscopically classify ultracool dwarfs and determine their effective temperature. In this line, we leveraged of the deep transfer learning framework introduced by \citet{masbuitrago2024} and explored its adaptation to the low-resolution, ultracool dwarf domain, with a view to its further application to the \textit{Euclid} dataset.


\section{Testbed environment with SpeX}


To adjust our methodology and prepare it to the arrival of the first spectroscopic data from \textit{Euclid}, we created a testbed environment using low-resolution spectra from the SpeX Prism Library, an online repository of over 3\,000 low-resolution, near-infrared spectra, primarily of ultracool dwarfs. The spectra available in the SpeX Prism Library were observed with the prism mode of the SpeX spectrograph \citep{Rayner2003} of the NASA Infrared Telescope Facility, with a resolving power $\sim200$ across $0.8-2.5$\,$\mu$m when using the 0.8\,arcsec slit. This repository is easily accessible using \texttt{SPLAT} \citep{splat}, a python-based access and analysis package designed to search for spectral data in the SpeX Prism Library and perform comprehensive spectral analysis. To obtain our sample of spectra, or target domain, we cross-matched the sample of high-quality ultracool dwarfs from the UltracoolSheet catalogue, presented in Section \ref{sec:ucds_intro}, with the SpeX Prism Library and obtained a final sample of 692 spectra with a spectroscopic classification in SpeX covering spectral types from M6 to T9.

As source domain for our deep transfer learning methodology, we built a grid of synthetic spectra based on the recent Sonora Elf Owl \citep{elfowl} substellar atmosphere models, which present developments in atmospheric chemistry compared to earlier model collections such as Sonora Bobcat \citep{bobcat} or Sonora Cholla \citep{cholla}. For this, we adjusted the Sonora Elf Owl models to the resolution and wavelength solution of SpeX\,\footnote{The adapted models are available in the \texttt{ucdmcmc} package of Dr. Adam Burgasser: \url{https://github.com/aburgasser/ucdmcmc/tree/main}}, and added three different random Gaussian noise values to each spectrum to enrich the dataset, ending up with a final synthetic grid of 31\,050 spectra (see Table 2 in \citealt{elfowl} for the grid of parameters). For both the synthetic and the observed spectra, we only considered the wavelength interval $12\,000-19\,000$\,\AA, since this will be the range covered by the \textit{Euclid} wide survey \citep{euclid2023}. Moreover, given the temperature constraints of the Sonora Elf Owl models, we retained only the SpeX spectra corresponding to spectral types M8 or later, and only kept the highest SNR spectrum when several were available for the same source. Doing this, we ended up with a sample of 585 SpeX spectra.

\section{Ultracool dwarf characterisation}

To determine the effective temperature of our sample of low-resolution, near-infrared ultracool dwarf spectra, we replicated the deep transfer learning methodology presented by \citet{masbuitrago2024}. First, we trained the autoencoder neural networks using the grid of synthetic spectra, obtaining reconstruction errors $\sim10^{-4}$ on the test set. Since the number of input features is significantly smaller than in \citet{masbuitrago2024} due to the lower resolution of the data, we adjusted the number of neurons in the input layer and reduced the number of hidden layers to two in the autoencoder architectures (see Fig. \ref{fig:ac_info}). For the knowledge transfer process, we fine-tuned the autoencoder neural networks with the SpeX spectra, tailoring the high-level features of the encoder network to our target domain. Figure \ref{fig:spex_reco} shows the importance of this step to adapt the autoencoder to our target domain, ensuring that the compressed representations obtained with the fine-tuned autoencoders are more meaningful than those obtained without the transfer learning process.

We used the low-dimensional representations of the Sonora Elf Owl and SpeX spectra, resulting from the initial training and the fine-tuning of the autoencoders, respectively, as input to the convolutional neural networks (see Fig. \ref{fig:cnn}) for the estimation of the effective temperature of our target sample. We calculated the minimum Euclidean and correlation distances  from each SpeX instance to the synthetic grid in both the initial high-dimensional space and the new low-dimensional feature space, obtaining a reduction of over an order of magnitude for the compressed low-dimensional representations, averaged over all the sets obtained from the different autoencoder architectures. In this way, we effectively bridge the gap between the two domains, and parameter estimation is conducted using a dataset in which discrepancies in feature distributions between the synthetic and observed data are reduced.


Figure \ref{fig:ucds_teff} reproduces the diagrams presented in Fig. \ref{fig:ucds_diag}, colouring the dots with the effective temperatures determined for our target sample to illustrate the temperature evolution of ultracool dwarfs. The near-infrared colour-magnitude diagram in the left panel shows how, when the trend changes abruptly to bluer $\textit{J}-\textit{H}$ values, the effective temperature of the ultracool dwarfs remains roughly constant at $\sim1450$\,K. During this L/T transition, visible in both panels as a plateau in $M_{\mathrm{J}}$, the effective temperature evolves very slowly \citep{golimovsky2004,kirkpatrick2021}, decreasing only $\sim200$\,K throughout the entire transition. Table \ref{tab:ucds_teffs} lists all the effective temperatures determined for our sample of ultracool dwarfs.

Figure \ref{fig:spex_spts_teff} shows the determined effective temperatures as a function of spectral type, together with the mean weighted with the uncertainties derived in this work and standard deviation for each of the spectral types (right panel), which are listed in Table \ref{tab:spt_teff_rel}. Both panels demonstrate how the temperature decreases steeply for spectral types M8-L7 and $\sim$T2-T9, with the well-known narrow range of effective temperature throughout the L/T transition. The right panel shows how the calculated effective temperatures are in general in very good agreement with the semi-empirical relations from \citet{kirkpatrick2021} and \citet{sanghi2023}. Our values are in average higher than the aforementioned relations during the L/T transition. Since \citet{sanghi2023} uses also uses a sample of ultracool dwarfs extracted from the UltracoolSheet catalogue, we can directly compare our effective temperature determinations with their semi-empirical values. Figure \ref{fig:teffs_comp_sanghi} illustrates this comparison, confirming a good consistency between the two sets and a deviation towards higher values in our temperatures for the L/T transition. This transition is still a less understood phase of ultracool dwarf evolution. The increase of cloud opacity from early-L to late-L dwarfs, and the evolution to cloudless T dwarfs, hugely complicates the modelling of these atmospheres. In the future, a better treatment of clouds for this transition in atmospheric models will be the key to mitigating this effect.

The results obtained in this study indicate that the methodology presented by \citet{masbuitrago2024}, developed for the determination of stellar parameters of M dwarfs from high-resolution spectra, can be successfully adapted to the low-resolution domain to estimate the effective temperature of ultracool dwarfs. In this line, the methodology consolidated in this chapter will serve as a basis for the characterisation of ultracool dwarfs in the promising surveys to come in the next years, which envisage a scientific leap in this field, starting with its direct application to the wide-field \textit{Euclid} low-resolution spectroscopic survey. We are already making progress in this regard, working with the first spectroscopic data from \textit{Euclid}, and have successfully tailored the procedure to its wavelength solution. Doing this, we have applied the methodology to near-infrared, low-resolution \textit{Euclid} spectra of a sample of confirmed ultracool dwarfs (see Figure \ref{fig:euclid}), and determined the effective temperatures of these objects, which are in excellent agreement with the spectral types derived by comparing them to the standard templates published by SPLAT (see Dominguez-Tagle et al. in press.).

%-------------------------------------------------------------------

%************************************************
\chapter{General conclusions and future work}
\label{chp:general_intro}

This thesis delves into the discovery and characterisation of low-mass objects from a data-driven perspective, providing a rich catalogue of ultracool dwarf candidates and a deep transfer learning methodology for the estimation of stellar parameters of M dwarfs that we hope will be of great value for the astronomical community to exploit. In recent years, astronomy is undergoing a paradigm shift driven by an exponential growth in observational data, with new-generation surveys that have produced vast amounts of information that have pushed traditional methods of data analysis to their limits. We address this challenge by exploring the application of machine and deep learning techniques, in combination with Virtual Observatory technologies, for the development of methodologies to advance our understanding of M dwarfs and ultracool dwarfs in the years to come. The results obtained reinforce the growing role of machine learning in astronomy, highlighting its transformative potential for handling large astronomical datasets, and advocate data-driven approaches that combine Virtual Observatory technologies with machine and deep learning techniques as the way forward for the future of observational astronomy. These results have led to the publication of three scientific papers in the course of this thesis: \citet{masbuitrago2022}, \citet{masbuitrago2024}, and \citet{masbuitrago2025}.

\section{Summary of the Thesis}

The primary contributions of this work are as follows:

\begin{itemize}

    \item This thesis has demonstrated how Virtual Observatory data mining technologies can be harnessed to streamline the discovery and characterisation of ultracool dwarfs. Combining multi-filter photometry from several surveys and astrometric data, we consolidated a Virtual Observatory methodology to efficiently identify ultracool dwarf candidates in wide-field surveys and subsequently characterise them. Using this approach, we provided a catalogue of ultracool dwarfs over the entire sky coverage of the J-PLUS second data release, increasing the number of ultracool dwarfs reported in this region by $\sim135$\,\%. We demonstrated how a machine learning approach could accelerate this process, which is an important achievement considering the application of this methodology to larger and deeper surveys such as J-PAS and \textit{Euclid}. In this sense, future work could be focused in mitigating the main limitations of the developed methodology, which is based on a combination of principal component analysis and support vector machines, namely the significant number of false positives obtained prior to the determination of the effective temperature. An approach involving cost-sensitive learning techniques \citep{cost_sensitive} could be the way forward.


    \item We consolidated a deep transfer learning approach, based on autoencoder neural networks, to determine atmospheric stellar parameters of M dwarfs from high-resolution spectra. Using this methodology, we provided new estimations for the effective temperature, surface gravity, metallicity, and projected rotational velocity for 286 M dwarfs observed by the CARMENES survey, mitigating the deviations in previous works attributed to the differences between synthetic and observed data. Since no other data than the observed spectra are required in the transfer learning process, our methodology proves to be very flexible and represents a significant step forward in bridging the synthetic gap in stellar parameter estimation from synthetic spectra. We further demonstrated this by successfully adapting the procedure to the low-resolution domain to estimate the effective temperature of ultracool dwarfs using near-infrared spectra from SpeX Prism Library.


    \item We demonstrated the potential of multi-filter photometric surveys to systematically detect flare events in M dwarfs. Combining Virtual Observatory capabilities to query huge amount of data and a flexible detection algorithm developed for this end, we managed to analyse millions of spectral energy distributions and obtain a sample of flaring M dwarfs. We confirmed and studied the flaring nature of these objects using low-resolution spectra collected with NOT/ALFOSC and GTC/OSIRIS, and high-cadence photometric data from TESS. This procedure, which can easily be used in other multi-filter photometric surveys, allowed the detection of episodes of strong Ca~{\sc ii} H and K line emission, which are not usually taken into account in the study of flares in large M dwarf samples and may have important implications for exoplanetary space weather and habitability studies.

\end{itemize}


The results of this thesis have broad implications for both stellar and substellar astrophysics. This work has contributed to expanding the census of ultracool dwarfs, which are among the least understood populations due to their intrinsic faintness and complex atmospheres, by employing a flexible and scalable Virtual Observatory approach that integrates multi-filter photometry and astrometric data. The newly identified 7\,827 candidates constitute valuable targets for follow-up observations and further refinement of ultracool dwarf population statistics. By identifying Ca~{\sc ii} H and K flaring M dwarfs, and a methodology to detect them in multi-filter photometric surveys, this thesis contributes to the ongoing discussion of how stellar activity affects the long-term viability of planetary systems around these stars, which are ubiquitous in the solar neighbourhood and are prime targets for exoplanet searches.

A persistent challenge in stellar astrophysics is the discrepancy between synthetic models and observed spectra. By using a deep transfer learning approach to project synthetic and observed data into a common feature space, this thesis consolidates a novel approach to overcoming the gap between them, improving the reliability of parameter estimation from synthetic spectra in low-mass objects with a flexible and scalable methodology that can be easily applied to the large surveys expected in the years to come. As machine learning becomes more widespread, it will continue to contribute to the development of astronomical data analysis methodologies, superseding or complementing traditional methods, enabling discoveries that would otherwise be difficult or impossible to achieve.

\section{Future Directions}

The methodologies developed in this thesis open up several promising avenues for future research. In this sense, future efforts should focus on scaling up these approaches and integrate them into the workflow of next-generation astronomical surveys such as J-PAS, \textit{Euclid} or LSST, which will dramatically increase the amount of data available. Since machine learning pipelines will play a crucial role in managing the vast datasets produced by these missions, the techniques developed in this thesis can be adapted to upcoming surveys to automate the discovery and characterisation of low-mass stellar and substellar objects.

The most direct application of the work developed in this thesis is the use of the deep transfer learning methodology presented in Chapters \ref{chp:autoencoders_paper} and \ref{chp:dtl_ucds} for the discovery and characterisation of ultracool dwarfs in the first data release of \textit{Euclid}, which will be publicly available in mid-2026. In this sense, we will go a step further in the methodology, taking advantage of the power of autoencoder architectures for outlier detection, to identify ultracool dwarfs using the whole dataset of low-resolution spectra from the \textit{Euclid} wide-field spectroscopic survey. This can be achieved by using autoencoder neural networks trained with a grid of synthetic spectra, and fine-tuned with real \textit{Euclid} spectra corresponding to well-known ultracool dwarfs. By analysing the reconstruction error of this system, we will study the use of a limiting value to discard all objects for which a significantly higher reconstruction error is obtained, which will make it possible to analyse huge amounts of spectroscopic data in a very efficient way, retaining only the ultracool objects of interest. A cornerstone of this process will be ESA Datalabs\,\footnote{\url{https://datalabs.esa.int/}}, a new infrastructure built around the ESA science archives that provides unique archival data access capabilities, bringing the solution to the data rather than the other way around, playing a pivotal role in the development of the aforementioned system due to the huge volume of data that will be processed. After the discovery phase, we will follow a procedure similar to that discussed in Chapter \ref{chp:dtl_ucds} to characterise the low-resolution spectra of the identified ultracool dwarfs, creating a rich catalogue of spectroscopically characterised ultracool dwarfs that could be of great value to the astronomical community. The main strength of this methodology lies in its ability to eliminate biases that are present in other classical methodologies, in which objects are first selected on the basis of colours and then its ultracool nature is confirmed using spectra. Furthermore, we plan to test this methodology using different sets of atmosphere and evolutionary models, such as the ATMO 2020 \citep{atmo2020}, to study in detail the differences with our current setup.

As the data tsunami in observational astronomy continues to grow, artificial intelligence will become increasingly essential in processing, analysing, and interpreting the information about our cosmos. This thesis has demonstrated how machine and deep learning-driven methods, combined with the infrastructure of the Virtual Observatory, can empower the discovery and characterisation of M dwarfs and ultracool dwarfs. The data-driven techniques developed in this work pave the way for the automation of astrophysical analysis in the low-mass regime, enabling researchers to fully exploit the potential of the vast and growing datasets expected by upcoming astronomical surveys.

%*******************************************************
% Data Availability
%*******************************************************

\chapter*{Data and Software Availability}\label{data_av}
\addcontentsline{toc}{chapter}{Data and Software Availability}

During the development of this thesis, we have endeavoured to build several publicly accessible catalogues, codes and tools that can be exploited by the astronomical community. To help the researchers use our catalogues of ultracool dwarfs presented in Chapter \ref{chp:ucds_paper}, we provide an archive system that can be accessed  from  a webpage\,\footnote{\url{http://svocats.cab.inta-csic.es/jplus_ucds1; http://svocats.cab.inta-csic.es/jplus_ucds2}} or through a Virtual Observatory ConeSearch\,\footnote{e.g.\url{http://svocats.cab.inta-csic.es/jplus_ucds1/cs.php?RA=0.023&DEC=35.457&SR=0.1&VERB=2; http://svocats.cab.inta-csic.es/jplus_ucds2/cs.php?RA=238.569&DEC=52.742&SR=0.1&VERB=2}}. The archive system implements a  very simple search interface that allows queries by coordinates and radius as well as by other parameters of interest. The user can also select the maximum number of sources (with values from ten to unlimited). The result can be obtained as an HTLM table or downloaded as a VOTable or a CSV file. Detailed information on the output fields can be obtained placing the mouse over the question mark located close to the name of the column. The archive also implements the SAMP\,\footnote{\url{http://www.ivoa.net/documents/SAMP}} (Simple Application Messaging) Virtual Observatory protocol, which allows Virtual Observatory applications to communicate with each other in a seamless and transparent manner for the user. In this way, the results of a query can be easily transferred to other Virtual Observatory applications, such as, for instance, \texttt{TOPCAT}.

All the resources presented in Chapter \ref{chp:autoencoders_paper}, including the code developed to build the methodology described in Section \ref{acs_sec:methodology} and the code to reproduce the figures displayed in Section \ref{acs_sec:results} are publicly available at \texttt{GitHub}\,\footnote{\url{https://github.com/pedromasb/autoencoders-CARMENES}}. The catalogue of stellar atmospheric parameters for 286 CARMENES M dwarfs determined using our deep transfer learning methodology is available at VizieR\,\footnote{\url{https://cdsarc.cds.unistra.fr/viz-bin/cat/J/A+A/687/A205}}, and we also provide a data discovery interface that allows its interactive exploration\,\footnote{\url{https://cab.inta-csic.es/users/pmas/}}. Moreover, the files with the reduced spectra and processed TESS light curves used in Chapter \ref{chp:flares_paper}, and the code to reproduce the figures displayed in Section \ref{sec:results} are publicly available at \texttt{GitHub\,}\footnote{\url{https://github.com/pedromasb/flaring-MDwarfs}}.

On the other hand, we have also carried out several parallel projects dedicated to bringing new data analysis technology closer to the user. The author has created several tutorials, available at \texttt{GitHub}\,\footnote{\url{https://github.com/pedromasb/tutorials}}, that cover useful Python features, and developed a tool help the user create and share interactive visualizations without the need to write any code\,\footnote{\url{https://magicplotter.streamlit.app/}}. Moreover, the author has contributed to the organisation and development of sessions at the Centro de Astrobiología, aimed at sharing knowledge about Python tips and modules that are generally useful in Astrophysics data analysis\,\footnote{\url{https://github.com/PyCoffees/notebooks}}.


\end{document}
